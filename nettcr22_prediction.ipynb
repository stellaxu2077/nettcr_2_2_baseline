{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index      A1       A2              A3      B1       B2              B3  \\\n",
      "0      0   KALYS  LLKGGEQ  GTEIGGGTSYGKLT   MNHEY   SMNVEV        ASGTETQY   \n",
      "1      1  DRGSQS   IYSNGD      AVNPANARLM  DFQATT  SNEGSKA    SARWGGGTDTQY   \n",
      "2      3  DRGSQS   IYSNGD      AVTPGTYKYI   LGHDT   YNNKEL  ASSPGTSIFVAEQY   \n",
      "\n",
      "     peptide       allele           origin  binder  partition  \\\n",
      "0  SPRWYFYYL  HLA-B*07:02  peptide_swapped       0          2   \n",
      "1  GILGFVFTL  HLA-A*02:01  peptide_swapped       0          3   \n",
      "2  KLGGALQAK  HLA-A*03:01  peptide_swapped       0          0   \n",
      "\n",
      "  original_peptide  original_index   10x reference  \n",
      "0        KLGGALQAK            2627  True  negative  \n",
      "1       ELAGIGILTV            3820  True  negative  \n",
      "2       ELAGIGILTV            5933  True  negative  \n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "#data = pd.read_csv('./data/IMMREP/train/all_peptides_redundancy_reduced.csv')\n",
    "data = pd.read_csv('./data/nettcr_2_2_limited_dataset.csv')\n",
    "print(data.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34352 entries, 0 to 34351\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   index             34352 non-null  int64 \n",
      " 1   A1                34352 non-null  object\n",
      " 2   A2                34352 non-null  object\n",
      " 3   A3                34352 non-null  object\n",
      " 4   B1                34352 non-null  object\n",
      " 5   B2                34352 non-null  object\n",
      " 6   B3                34352 non-null  object\n",
      " 7   peptide           34352 non-null  object\n",
      " 8   allele            34352 non-null  object\n",
      " 9   origin            34352 non-null  object\n",
      " 10  binder            34352 non-null  int64 \n",
      " 11  partition         34352 non-null  int64 \n",
      " 12  original_peptide  34352 non-null  object\n",
      " 13  original_index    34352 non-null  int64 \n",
      " 14  10x               34352 non-null  bool  \n",
      " 15  reference         33949 non-null  object\n",
      "dtypes: bool(1), int64(4), object(11)\n",
      "memory usage: 4.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                 0\n",
      "A1                    0\n",
      "A2                    0\n",
      "A3                    0\n",
      "B1                    0\n",
      "B2                    0\n",
      "B3                    0\n",
      "peptide               0\n",
      "allele                0\n",
      "origin                0\n",
      "binder                0\n",
      "partition             0\n",
      "original_peptide      0\n",
      "original_index        0\n",
      "10x                   0\n",
      "reference           403\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 22:58:44.565826: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "86/86 [==============================] - 4s 15ms/step - loss: 0.4862 - auc_01: 0.5022 - auc: 0.5092 - val_loss: 0.4538 - val_auc_01: 0.5162 - val_auc: 0.5519\n",
      "Epoch 2/200\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.4477 - auc_01: 0.5127 - auc: 0.5132 - val_loss: 0.4524 - val_auc_01: 0.5093 - val_auc: 0.5497\n",
      "Epoch 3/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4473 - auc_01: 0.5078 - auc: 0.5066 - val_loss: 0.4529 - val_auc_01: 0.5035 - val_auc: 0.5335\n",
      "Epoch 4/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4477 - auc_01: 0.5048 - auc: 0.5004 - val_loss: 0.4548 - val_auc_01: 0.5180 - val_auc: 0.5297\n",
      "Epoch 5/200\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.4472 - auc_01: 0.5102 - auc: 0.5051 - val_loss: 0.4525 - val_auc_01: 0.5161 - val_auc: 0.5462\n",
      "Epoch 6/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4457 - auc_01: 0.5115 - auc: 0.5225 - val_loss: 0.4500 - val_auc_01: 0.5168 - val_auc: 0.5494\n",
      "Epoch 7/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4461 - auc_01: 0.5127 - auc: 0.5139 - val_loss: 0.4508 - val_auc_01: 0.5163 - val_auc: 0.5505\n",
      "Epoch 8/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4453 - auc_01: 0.5152 - auc: 0.5267 - val_loss: 0.4530 - val_auc_01: 0.5166 - val_auc: 0.5480\n",
      "Epoch 9/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4439 - auc_01: 0.5181 - auc: 0.5355 - val_loss: 0.4495 - val_auc_01: 0.5246 - val_auc: 0.5581\n",
      "Epoch 10/200\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.4438 - auc_01: 0.5155 - auc: 0.5355 - val_loss: 0.4528 - val_auc_01: 0.5220 - val_auc: 0.5344\n",
      "Epoch 11/200\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.4453 - auc_01: 0.5181 - auc: 0.5207 - val_loss: 0.4499 - val_auc_01: 0.5188 - val_auc: 0.5451\n",
      "Epoch 12/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4432 - auc_01: 0.5246 - auc: 0.5482 - val_loss: 0.4500 - val_auc_01: 0.5195 - val_auc: 0.5563\n",
      "Epoch 13/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4412 - auc_01: 0.5256 - auc: 0.5509 - val_loss: 0.4484 - val_auc_01: 0.5180 - val_auc: 0.5398\n",
      "Epoch 14/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4392 - auc_01: 0.5271 - auc: 0.5562 - val_loss: 0.4451 - val_auc_01: 0.5249 - val_auc: 0.5709\n",
      "Epoch 15/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4399 - auc_01: 0.5242 - auc: 0.5641 - val_loss: 0.4493 - val_auc_01: 0.5245 - val_auc: 0.5527\n",
      "Epoch 16/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4376 - auc_01: 0.5271 - auc: 0.5729 - val_loss: 0.4424 - val_auc_01: 0.5249 - val_auc: 0.5792\n",
      "Epoch 17/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4358 - auc_01: 0.5326 - auc: 0.5768 - val_loss: 0.4444 - val_auc_01: 0.5325 - val_auc: 0.5937\n",
      "Epoch 18/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4307 - auc_01: 0.5372 - auc: 0.6106 - val_loss: 0.4362 - val_auc_01: 0.5326 - val_auc: 0.6294\n",
      "Epoch 19/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4274 - auc_01: 0.5448 - auc: 0.6260 - val_loss: 0.4360 - val_auc_01: 0.5325 - val_auc: 0.6574\n",
      "Epoch 20/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4257 - auc_01: 0.5420 - auc: 0.6397 - val_loss: 0.4328 - val_auc_01: 0.5345 - val_auc: 0.6570\n",
      "Epoch 21/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4149 - auc_01: 0.5541 - auc: 0.6788 - val_loss: 0.4314 - val_auc_01: 0.5602 - val_auc: 0.6892\n",
      "Epoch 22/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4118 - auc_01: 0.5685 - auc: 0.6940 - val_loss: 0.4237 - val_auc_01: 0.5455 - val_auc: 0.6903\n",
      "Epoch 23/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.4038 - auc_01: 0.5772 - auc: 0.7103 - val_loss: 0.4118 - val_auc_01: 0.5590 - val_auc: 0.7318\n",
      "Epoch 24/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3953 - auc_01: 0.5990 - auc: 0.7324 - val_loss: 0.4078 - val_auc_01: 0.6071 - val_auc: 0.7452\n",
      "Epoch 25/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3848 - auc_01: 0.6184 - auc: 0.7619 - val_loss: 0.3953 - val_auc_01: 0.6333 - val_auc: 0.7611\n",
      "Epoch 26/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3791 - auc_01: 0.6362 - auc: 0.7703 - val_loss: 0.3921 - val_auc_01: 0.6317 - val_auc: 0.7506\n",
      "Epoch 27/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3696 - auc_01: 0.6482 - auc: 0.7847 - val_loss: 0.3886 - val_auc_01: 0.6426 - val_auc: 0.7650\n",
      "Epoch 28/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3609 - auc_01: 0.6572 - auc: 0.7911 - val_loss: 0.3866 - val_auc_01: 0.6414 - val_auc: 0.7715\n",
      "Epoch 29/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3616 - auc_01: 0.6505 - auc: 0.7927 - val_loss: 0.3808 - val_auc_01: 0.6576 - val_auc: 0.7720\n",
      "Epoch 30/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3561 - auc_01: 0.6576 - auc: 0.8023 - val_loss: 0.3804 - val_auc_01: 0.6470 - val_auc: 0.7754\n",
      "Epoch 31/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3498 - auc_01: 0.6716 - auc: 0.8093 - val_loss: 0.3776 - val_auc_01: 0.6495 - val_auc: 0.7840\n",
      "Epoch 32/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3475 - auc_01: 0.6665 - auc: 0.8115 - val_loss: 0.3761 - val_auc_01: 0.6482 - val_auc: 0.7859\n",
      "Epoch 33/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3423 - auc_01: 0.6761 - auc: 0.8171 - val_loss: 0.3911 - val_auc_01: 0.6448 - val_auc: 0.7744\n",
      "Epoch 34/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3372 - auc_01: 0.6802 - auc: 0.8210 - val_loss: 0.3750 - val_auc_01: 0.6606 - val_auc: 0.7852\n",
      "Epoch 35/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3330 - auc_01: 0.6778 - auc: 0.8300 - val_loss: 0.3667 - val_auc_01: 0.6602 - val_auc: 0.7996\n",
      "Epoch 36/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3290 - auc_01: 0.6872 - auc: 0.8345 - val_loss: 0.3744 - val_auc_01: 0.6616 - val_auc: 0.7910\n",
      "Epoch 37/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3291 - auc_01: 0.6912 - auc: 0.8377 - val_loss: 0.3757 - val_auc_01: 0.6673 - val_auc: 0.7907\n",
      "Epoch 38/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.3254 - auc_01: 0.6966 - auc: 0.8396 - val_loss: 0.3685 - val_auc_01: 0.6630 - val_auc: 0.7971\n",
      "Epoch 39/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3188 - auc_01: 0.6989 - auc: 0.8403 - val_loss: 0.3747 - val_auc_01: 0.6555 - val_auc: 0.7898\n",
      "Epoch 40/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3117 - auc_01: 0.7021 - auc: 0.8513 - val_loss: 0.3874 - val_auc_01: 0.6575 - val_auc: 0.7827\n",
      "Epoch 41/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3156 - auc_01: 0.7117 - auc: 0.8494 - val_loss: 0.3841 - val_auc_01: 0.6531 - val_auc: 0.7916\n",
      "Epoch 42/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.2952 - auc_01: 0.7266 - auc: 0.8691 - val_loss: 0.3860 - val_auc_01: 0.6636 - val_auc: 0.7902\n",
      "Epoch 43/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2922 - auc_01: 0.7210 - auc: 0.8744 - val_loss: 0.3830 - val_auc_01: 0.6671 - val_auc: 0.7878\n",
      "Epoch 44/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.3032 - auc_01: 0.7224 - auc: 0.8635 - val_loss: 0.3679 - val_auc_01: 0.6658 - val_auc: 0.8101\n",
      "Epoch 45/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2934 - auc_01: 0.7268 - auc: 0.8765 - val_loss: 0.3654 - val_auc_01: 0.6712 - val_auc: 0.8059\n",
      "Epoch 46/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2931 - auc_01: 0.7305 - auc: 0.8710 - val_loss: 0.3762 - val_auc_01: 0.6695 - val_auc: 0.8028\n",
      "Epoch 47/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2846 - auc_01: 0.7214 - auc: 0.8785 - val_loss: 0.3834 - val_auc_01: 0.6643 - val_auc: 0.7987\n",
      "Epoch 48/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2817 - auc_01: 0.7425 - auc: 0.8866 - val_loss: 0.3748 - val_auc_01: 0.6621 - val_auc: 0.8029\n",
      "Epoch 49/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2785 - auc_01: 0.7495 - auc: 0.8872 - val_loss: 0.3688 - val_auc_01: 0.6686 - val_auc: 0.8112\n",
      "Epoch 50/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2783 - auc_01: 0.7507 - auc: 0.8832 - val_loss: 0.3743 - val_auc_01: 0.6668 - val_auc: 0.8083\n",
      "Epoch 51/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2741 - auc_01: 0.7491 - auc: 0.8891 - val_loss: 0.3842 - val_auc_01: 0.6696 - val_auc: 0.8015\n",
      "Epoch 52/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2606 - auc_01: 0.7667 - auc: 0.9004 - val_loss: 0.3751 - val_auc_01: 0.6711 - val_auc: 0.8121\n",
      "Epoch 53/200\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.2654 - auc_01: 0.7687 - auc: 0.8944 - val_loss: 0.3809 - val_auc_01: 0.6709 - val_auc: 0.8071\n",
      "Epoch 54/200\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.2591 - auc_01: 0.7616 - auc: 0.9025 - val_loss: 0.3736 - val_auc_01: 0.6785 - val_auc: 0.8123\n",
      "Epoch 55/200\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.2604 - auc_01: 0.7563 - auc: 0.8989 - val_loss: 0.3774 - val_auc_01: 0.6738 - val_auc: 0.8081\n",
      "Epoch 56/200\n",
      "86/86 [==============================] - 2s 22ms/step - loss: 0.2592 - auc_01: 0.7564 - auc: 0.9060 - val_loss: 0.4091 - val_auc_01: 0.6718 - val_auc: 0.7967\n",
      "Epoch 57/200\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.2540 - auc_01: 0.7780 - auc: 0.9066 - val_loss: 0.3858 - val_auc_01: 0.6833 - val_auc: 0.8078\n",
      "Epoch 58/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2584 - auc_01: 0.7656 - auc: 0.9006 - val_loss: 0.3863 - val_auc_01: 0.6734 - val_auc: 0.8134\n",
      "Epoch 59/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2466 - auc_01: 0.7855 - auc: 0.9083 - val_loss: 0.3789 - val_auc_01: 0.6775 - val_auc: 0.8167\n",
      "Epoch 60/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2425 - auc_01: 0.7817 - auc: 0.9112 - val_loss: 0.4021 - val_auc_01: 0.6668 - val_auc: 0.7983\n",
      "Epoch 61/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2433 - auc_01: 0.7827 - auc: 0.9110 - val_loss: 0.4004 - val_auc_01: 0.6774 - val_auc: 0.7989\n",
      "Epoch 62/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2366 - auc_01: 0.7871 - auc: 0.9166 - val_loss: 0.3836 - val_auc_01: 0.6833 - val_auc: 0.8113\n",
      "Epoch 63/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2397 - auc_01: 0.7882 - auc: 0.9156 - val_loss: 0.3896 - val_auc_01: 0.6748 - val_auc: 0.8112\n",
      "Epoch 64/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2461 - auc_01: 0.7765 - auc: 0.9090 - val_loss: 0.3937 - val_auc_01: 0.6735 - val_auc: 0.8121\n",
      "Epoch 65/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2400 - auc_01: 0.7896 - auc: 0.9144 - val_loss: 0.3967 - val_auc_01: 0.6819 - val_auc: 0.8075\n",
      "Epoch 66/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2279 - auc_01: 0.8034 - auc: 0.9235 - val_loss: 0.3907 - val_auc_01: 0.6788 - val_auc: 0.8122\n",
      "Epoch 67/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2211 - auc_01: 0.8014 - auc: 0.9276 - val_loss: 0.3887 - val_auc_01: 0.6801 - val_auc: 0.8122\n",
      "Epoch 68/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2292 - auc_01: 0.8031 - auc: 0.9217 - val_loss: 0.3861 - val_auc_01: 0.6860 - val_auc: 0.8169\n",
      "Epoch 69/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2217 - auc_01: 0.8059 - auc: 0.9270 - val_loss: 0.3920 - val_auc_01: 0.6753 - val_auc: 0.8144\n",
      "Epoch 70/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2295 - auc_01: 0.8040 - auc: 0.9217 - val_loss: 0.3816 - val_auc_01: 0.6780 - val_auc: 0.8219\n",
      "Epoch 71/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2256 - auc_01: 0.8061 - auc: 0.9240 - val_loss: 0.3906 - val_auc_01: 0.6814 - val_auc: 0.8179\n",
      "Epoch 72/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2168 - auc_01: 0.8270 - auc: 0.9315 - val_loss: 0.4033 - val_auc_01: 0.6758 - val_auc: 0.8042\n",
      "Epoch 73/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2214 - auc_01: 0.8141 - auc: 0.9286 - val_loss: 0.4210 - val_auc_01: 0.6751 - val_auc: 0.8032\n",
      "Epoch 74/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2201 - auc_01: 0.8106 - auc: 0.9277 - val_loss: 0.4051 - val_auc_01: 0.6789 - val_auc: 0.8087\n",
      "Epoch 75/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2105 - auc_01: 0.8200 - auc: 0.9348 - val_loss: 0.4099 - val_auc_01: 0.6785 - val_auc: 0.8074\n",
      "Epoch 76/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2180 - auc_01: 0.8176 - auc: 0.9317 - val_loss: 0.4090 - val_auc_01: 0.6873 - val_auc: 0.8056\n",
      "Epoch 77/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2144 - auc_01: 0.8207 - auc: 0.9305 - val_loss: 0.3962 - val_auc_01: 0.6721 - val_auc: 0.8156\n",
      "Epoch 78/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2030 - auc_01: 0.8299 - auc: 0.9377 - val_loss: 0.4404 - val_auc_01: 0.6783 - val_auc: 0.7964\n",
      "Epoch 79/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2106 - auc_01: 0.8084 - auc: 0.9343 - val_loss: 0.4153 - val_auc_01: 0.6755 - val_auc: 0.8070\n",
      "Epoch 80/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2084 - auc_01: 0.8214 - auc: 0.9359 - val_loss: 0.4032 - val_auc_01: 0.6804 - val_auc: 0.8148\n",
      "Epoch 81/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2052 - auc_01: 0.8259 - auc: 0.9401 - val_loss: 0.4128 - val_auc_01: 0.6827 - val_auc: 0.8086\n",
      "Epoch 82/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2071 - auc_01: 0.8262 - auc: 0.9381 - val_loss: 0.4071 - val_auc_01: 0.6799 - val_auc: 0.8154\n",
      "Epoch 83/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2044 - auc_01: 0.8256 - auc: 0.9378 - val_loss: 0.4082 - val_auc_01: 0.6845 - val_auc: 0.8118\n",
      "Epoch 84/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1963 - auc_01: 0.8384 - auc: 0.9451 - val_loss: 0.4073 - val_auc_01: 0.6916 - val_auc: 0.8186\n",
      "Epoch 85/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1988 - auc_01: 0.8380 - auc: 0.9424 - val_loss: 0.4382 - val_auc_01: 0.6895 - val_auc: 0.7991\n",
      "Epoch 86/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1990 - auc_01: 0.8340 - auc: 0.9441 - val_loss: 0.4102 - val_auc_01: 0.6883 - val_auc: 0.8209\n",
      "Epoch 87/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1907 - auc_01: 0.8436 - auc: 0.9458 - val_loss: 0.4293 - val_auc_01: 0.6917 - val_auc: 0.8109\n",
      "Epoch 88/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1995 - auc_01: 0.8424 - auc: 0.9418 - val_loss: 0.4117 - val_auc_01: 0.6892 - val_auc: 0.8203\n",
      "Epoch 89/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1984 - auc_01: 0.8330 - auc: 0.9407 - val_loss: 0.4192 - val_auc_01: 0.6871 - val_auc: 0.8123\n",
      "Epoch 90/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1953 - auc_01: 0.8423 - auc: 0.9442 - val_loss: 0.4108 - val_auc_01: 0.6885 - val_auc: 0.8199\n",
      "Epoch 91/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1966 - auc_01: 0.8406 - auc: 0.9451 - val_loss: 0.4082 - val_auc_01: 0.6874 - val_auc: 0.8220\n",
      "Epoch 92/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1833 - auc_01: 0.8491 - auc: 0.9503 - val_loss: 0.4213 - val_auc_01: 0.6864 - val_auc: 0.8143\n",
      "Epoch 93/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1909 - auc_01: 0.8434 - auc: 0.9480 - val_loss: 0.4286 - val_auc_01: 0.6870 - val_auc: 0.8062\n",
      "Epoch 94/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1906 - auc_01: 0.8440 - auc: 0.9447 - val_loss: 0.4355 - val_auc_01: 0.6860 - val_auc: 0.8081\n",
      "Epoch 95/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1865 - auc_01: 0.8536 - auc: 0.9492 - val_loss: 0.4476 - val_auc_01: 0.6871 - val_auc: 0.8090\n",
      "Epoch 96/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1746 - auc_01: 0.8580 - auc: 0.9550 - val_loss: 0.4547 - val_auc_01: 0.6789 - val_auc: 0.8060\n",
      "Epoch 97/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1878 - auc_01: 0.8512 - auc: 0.9493 - val_loss: 0.4389 - val_auc_01: 0.6870 - val_auc: 0.8137\n",
      "Epoch 98/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1793 - auc_01: 0.8606 - auc: 0.9498 - val_loss: 0.4507 - val_auc_01: 0.6837 - val_auc: 0.8049\n",
      "Epoch 99/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1811 - auc_01: 0.8477 - auc: 0.9529 - val_loss: 0.4351 - val_auc_01: 0.6844 - val_auc: 0.8189\n",
      "Epoch 100/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1772 - auc_01: 0.8628 - auc: 0.9542 - val_loss: 0.4430 - val_auc_01: 0.6869 - val_auc: 0.8125\n",
      "Epoch 101/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1819 - auc_01: 0.8512 - auc: 0.9508 - val_loss: 0.4481 - val_auc_01: 0.6921 - val_auc: 0.8055\n",
      "Epoch 102/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1754 - auc_01: 0.8656 - auc: 0.9551 - val_loss: 0.4472 - val_auc_01: 0.6839 - val_auc: 0.8128\n",
      "Epoch 103/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1782 - auc_01: 0.8599 - auc: 0.9537 - val_loss: 0.4353 - val_auc_01: 0.6907 - val_auc: 0.8162\n",
      "Epoch 104/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1749 - auc_01: 0.8729 - auc: 0.9547 - val_loss: 0.4236 - val_auc_01: 0.6884 - val_auc: 0.8219\n",
      "Epoch 105/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1756 - auc_01: 0.8679 - auc: 0.9570 - val_loss: 0.4481 - val_auc_01: 0.6859 - val_auc: 0.8081\n",
      "Epoch 106/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1776 - auc_01: 0.8645 - auc: 0.9550 - val_loss: 0.4572 - val_auc_01: 0.6928 - val_auc: 0.8070\n",
      "Epoch 107/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1667 - auc_01: 0.8637 - auc: 0.9575 - val_loss: 0.4499 - val_auc_01: 0.6862 - val_auc: 0.8098\n",
      "Epoch 108/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1734 - auc_01: 0.8677 - auc: 0.9555 - val_loss: 0.4473 - val_auc_01: 0.6932 - val_auc: 0.8100\n",
      "Epoch 109/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1746 - auc_01: 0.8646 - auc: 0.9554 - val_loss: 0.4363 - val_auc_01: 0.6907 - val_auc: 0.8195\n",
      "Epoch 110/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1598 - auc_01: 0.8864 - auc: 0.9619 - val_loss: 0.4411 - val_auc_01: 0.6874 - val_auc: 0.8194\n",
      "Epoch 111/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1689 - auc_01: 0.8747 - auc: 0.9608 - val_loss: 0.4380 - val_auc_01: 0.6898 - val_auc: 0.8147\n",
      "Epoch 112/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1651 - auc_01: 0.8748 - auc: 0.9605 - val_loss: 0.4355 - val_auc_01: 0.6840 - val_auc: 0.8225\n",
      "Epoch 113/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1660 - auc_01: 0.8757 - auc: 0.9605 - val_loss: 0.4466 - val_auc_01: 0.6879 - val_auc: 0.8178\n",
      "Epoch 114/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1636 - auc_01: 0.8677 - auc: 0.9603 - val_loss: 0.4439 - val_auc_01: 0.6894 - val_auc: 0.8174\n",
      "Epoch 115/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1627 - auc_01: 0.8782 - auc: 0.9626 - val_loss: 0.4530 - val_auc_01: 0.6796 - val_auc: 0.8150\n",
      "Epoch 116/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1572 - auc_01: 0.8879 - auc: 0.9640 - val_loss: 0.4587 - val_auc_01: 0.6813 - val_auc: 0.8122\n",
      "Epoch 117/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1620 - auc_01: 0.8666 - auc: 0.9613 - val_loss: 0.4449 - val_auc_01: 0.6820 - val_auc: 0.8183\n",
      "Epoch 118/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1631 - auc_01: 0.8771 - auc: 0.9611 - val_loss: 0.4428 - val_auc_01: 0.6878 - val_auc: 0.8186\n",
      "Epoch 119/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1579 - auc_01: 0.8803 - auc: 0.9659 - val_loss: 0.4499 - val_auc_01: 0.6915 - val_auc: 0.8187\n",
      "Epoch 120/200\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.1569 - auc_01: 0.8832 - auc: 0.9628 - val_loss: 0.4402 - val_auc_01: 0.6942 - val_auc: 0.8208\n",
      "Epoch 121/200\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.1639 - auc_01: 0.8806 - auc: 0.9615 - val_loss: 0.4532 - val_auc_01: 0.6936 - val_auc: 0.8139\n",
      "Epoch 122/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1505 - auc_01: 0.8935 - auc: 0.9647 - val_loss: 0.4715 - val_auc_01: 0.6920 - val_auc: 0.8107\n",
      "Epoch 123/200\n",
      "86/86 [==============================] - 2s 17ms/step - loss: 0.1575 - auc_01: 0.8809 - auc: 0.9665 - val_loss: 0.4476 - val_auc_01: 0.6855 - val_auc: 0.8200\n",
      "Epoch 124/200\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.1607 - auc_01: 0.8821 - auc: 0.9621 - val_loss: 0.4579 - val_auc_01: 0.6924 - val_auc: 0.8123\n",
      "Epoch 125/200\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.1534 - auc_01: 0.8823 - auc: 0.9641 - val_loss: 0.4613 - val_auc_01: 0.6888 - val_auc: 0.8155\n",
      "Epoch 126/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1559 - auc_01: 0.8871 - auc: 0.9651 - val_loss: 0.4631 - val_auc_01: 0.6887 - val_auc: 0.8149\n",
      "Epoch 127/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1591 - auc_01: 0.8759 - auc: 0.9632 - val_loss: 0.4598 - val_auc_01: 0.6915 - val_auc: 0.8175\n",
      "Epoch 128/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1554 - auc_01: 0.8891 - auc: 0.9675 - val_loss: 0.4658 - val_auc_01: 0.6870 - val_auc: 0.8179\n",
      "Epoch 129/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1504 - auc_01: 0.8997 - auc: 0.9654 - val_loss: 0.4687 - val_auc_01: 0.6870 - val_auc: 0.8151\n",
      "Epoch 130/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1501 - auc_01: 0.8896 - auc: 0.9669 - val_loss: 0.4611 - val_auc_01: 0.6907 - val_auc: 0.8164\n",
      "Epoch 131/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1471 - auc_01: 0.8986 - auc: 0.9655 - val_loss: 0.4601 - val_auc_01: 0.6852 - val_auc: 0.8195\n",
      "Epoch 132/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1492 - auc_01: 0.8923 - auc: 0.9679 - val_loss: 0.4799 - val_auc_01: 0.6872 - val_auc: 0.8124\n",
      "Epoch 133/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1449 - auc_01: 0.8979 - auc: 0.9693 - val_loss: 0.4887 - val_auc_01: 0.6886 - val_auc: 0.8104\n",
      "Epoch 134/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1506 - auc_01: 0.8963 - auc: 0.9661 - val_loss: 0.4492 - val_auc_01: 0.6913 - val_auc: 0.8176\n",
      "Epoch 135/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1536 - auc_01: 0.8881 - auc: 0.9681 - val_loss: 0.4726 - val_auc_01: 0.6825 - val_auc: 0.8055\n",
      "Epoch 136/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1454 - auc_01: 0.8929 - auc: 0.9673 - val_loss: 0.4734 - val_auc_01: 0.6860 - val_auc: 0.8094\n",
      "Epoch 137/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1392 - auc_01: 0.9093 - auc: 0.9714 - val_loss: 0.4733 - val_auc_01: 0.6789 - val_auc: 0.8119\n",
      "Epoch 138/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1378 - auc_01: 0.9086 - auc: 0.9724 - val_loss: 0.4908 - val_auc_01: 0.6874 - val_auc: 0.8110\n",
      "Epoch 139/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1442 - auc_01: 0.8950 - auc: 0.9688 - val_loss: 0.4855 - val_auc_01: 0.6842 - val_auc: 0.8101\n",
      "Epoch 140/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1392 - auc_01: 0.9024 - auc: 0.9723 - val_loss: 0.4792 - val_auc_01: 0.6939 - val_auc: 0.8108\n",
      "Epoch 141/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1372 - auc_01: 0.9041 - auc: 0.9713 - val_loss: 0.4743 - val_auc_01: 0.6867 - val_auc: 0.8154\n",
      "Epoch 142/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1430 - auc_01: 0.8985 - auc: 0.9701 - val_loss: 0.4540 - val_auc_01: 0.6927 - val_auc: 0.8265\n",
      "Epoch 143/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1391 - auc_01: 0.9049 - auc: 0.9732 - val_loss: 0.4558 - val_auc_01: 0.6868 - val_auc: 0.8229\n",
      "Epoch 144/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1478 - auc_01: 0.8936 - auc: 0.9685 - val_loss: 0.4827 - val_auc_01: 0.6862 - val_auc: 0.8114\n",
      "Epoch 145/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1344 - auc_01: 0.9150 - auc: 0.9730 - val_loss: 0.4697 - val_auc_01: 0.6841 - val_auc: 0.8192\n",
      "Epoch 146/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1343 - auc_01: 0.9118 - auc: 0.9742 - val_loss: 0.4826 - val_auc_01: 0.6922 - val_auc: 0.8180\n",
      "Epoch 147/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1430 - auc_01: 0.9016 - auc: 0.9701 - val_loss: 0.4678 - val_auc_01: 0.6923 - val_auc: 0.8204\n",
      "Epoch 148/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1433 - auc_01: 0.8987 - auc: 0.9721 - val_loss: 0.4881 - val_auc_01: 0.6901 - val_auc: 0.8126\n",
      "Epoch 149/200\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.1379 - auc_01: 0.9083 - auc: 0.9714 - val_loss: 0.4862 - val_auc_01: 0.6973 - val_auc: 0.8170\n",
      "Epoch 150/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1367 - auc_01: 0.9092 - auc: 0.9743 - val_loss: 0.4849 - val_auc_01: 0.6905 - val_auc: 0.8132\n",
      "Epoch 151/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1396 - auc_01: 0.9031 - auc: 0.9722 - val_loss: 0.5014 - val_auc_01: 0.6946 - val_auc: 0.8085\n",
      "Epoch 152/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1312 - auc_01: 0.9112 - auc: 0.9750 - val_loss: 0.4868 - val_auc_01: 0.6860 - val_auc: 0.8073\n",
      "Epoch 153/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1449 - auc_01: 0.9049 - auc: 0.9700 - val_loss: 0.4895 - val_auc_01: 0.6918 - val_auc: 0.8169\n",
      "Epoch 154/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1476 - auc_01: 0.8982 - auc: 0.9704 - val_loss: 0.4921 - val_auc_01: 0.6960 - val_auc: 0.8102\n",
      "Epoch 155/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1363 - auc_01: 0.8933 - auc: 0.9731 - val_loss: 0.4765 - val_auc_01: 0.6907 - val_auc: 0.8245\n",
      "Epoch 156/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1373 - auc_01: 0.9074 - auc: 0.9724 - val_loss: 0.4898 - val_auc_01: 0.6889 - val_auc: 0.8157\n",
      "Epoch 157/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1280 - auc_01: 0.9154 - auc: 0.9758 - val_loss: 0.4947 - val_auc_01: 0.6859 - val_auc: 0.8161\n",
      "Epoch 158/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1370 - auc_01: 0.9045 - auc: 0.9727 - val_loss: 0.4828 - val_auc_01: 0.6841 - val_auc: 0.8158\n",
      "Epoch 159/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1382 - auc_01: 0.9091 - auc: 0.9725 - val_loss: 0.4952 - val_auc_01: 0.6907 - val_auc: 0.8181\n",
      "Epoch 160/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1282 - auc_01: 0.9181 - auc: 0.9762 - val_loss: 0.5164 - val_auc_01: 0.6848 - val_auc: 0.8093\n",
      "Epoch 161/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1305 - auc_01: 0.9092 - auc: 0.9753 - val_loss: 0.5039 - val_auc_01: 0.6912 - val_auc: 0.8084\n",
      "Epoch 162/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1230 - auc_01: 0.9143 - auc: 0.9778 - val_loss: 0.5204 - val_auc_01: 0.6872 - val_auc: 0.8056\n",
      "Epoch 163/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1226 - auc_01: 0.9206 - auc: 0.9785 - val_loss: 0.5022 - val_auc_01: 0.6949 - val_auc: 0.8160\n",
      "Epoch 164/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1280 - auc_01: 0.9168 - auc: 0.9761 - val_loss: 0.4952 - val_auc_01: 0.6884 - val_auc: 0.8151\n",
      "Epoch 165/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1247 - auc_01: 0.9231 - auc: 0.9798 - val_loss: 0.5301 - val_auc_01: 0.6936 - val_auc: 0.8012\n",
      "Epoch 166/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1267 - auc_01: 0.9152 - auc: 0.9781 - val_loss: 0.5710 - val_auc_01: 0.6861 - val_auc: 0.7931\n",
      "Epoch 167/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1303 - auc_01: 0.9115 - auc: 0.9753 - val_loss: 0.5083 - val_auc_01: 0.6947 - val_auc: 0.8161\n",
      "Epoch 168/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1247 - auc_01: 0.9265 - auc: 0.9777 - val_loss: 0.5023 - val_auc_01: 0.6909 - val_auc: 0.8163\n",
      "Epoch 169/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1211 - auc_01: 0.9229 - auc: 0.9772 - val_loss: 0.5055 - val_auc_01: 0.6924 - val_auc: 0.8126\n",
      "Epoch 170/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1274 - auc_01: 0.9134 - auc: 0.9780 - val_loss: 0.5260 - val_auc_01: 0.6894 - val_auc: 0.8129\n",
      "Epoch 171/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1216 - auc_01: 0.9228 - auc: 0.9784 - val_loss: 0.5166 - val_auc_01: 0.6899 - val_auc: 0.8108\n",
      "Epoch 172/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1192 - auc_01: 0.9203 - auc: 0.9797 - val_loss: 0.5070 - val_auc_01: 0.6882 - val_auc: 0.8102\n",
      "Epoch 173/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1210 - auc_01: 0.9254 - auc: 0.9789 - val_loss: 0.4968 - val_auc_01: 0.6900 - val_auc: 0.8148\n",
      "Epoch 174/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1166 - auc_01: 0.9265 - auc: 0.9809 - val_loss: 0.5044 - val_auc_01: 0.6884 - val_auc: 0.8155\n",
      "Epoch 175/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1164 - auc_01: 0.9281 - auc: 0.9802 - val_loss: 0.5045 - val_auc_01: 0.6851 - val_auc: 0.8129\n",
      "Epoch 176/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1214 - auc_01: 0.9298 - auc: 0.9799 - val_loss: 0.5182 - val_auc_01: 0.6846 - val_auc: 0.8122\n",
      "Epoch 177/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1216 - auc_01: 0.9257 - auc: 0.9778 - val_loss: 0.5198 - val_auc_01: 0.6918 - val_auc: 0.8129\n",
      "Epoch 178/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1115 - auc_01: 0.9341 - auc: 0.9832 - val_loss: 0.5232 - val_auc_01: 0.6888 - val_auc: 0.8117\n",
      "Epoch 179/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1208 - auc_01: 0.9244 - auc: 0.9783 - val_loss: 0.5298 - val_auc_01: 0.6900 - val_auc: 0.8059\n",
      "Epoch 180/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1145 - auc_01: 0.9270 - auc: 0.9817 - val_loss: 0.5092 - val_auc_01: 0.6869 - val_auc: 0.8131\n",
      "Epoch 181/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1180 - auc_01: 0.9286 - auc: 0.9800 - val_loss: 0.5197 - val_auc_01: 0.6909 - val_auc: 0.8124\n",
      "Epoch 182/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1269 - auc_01: 0.9141 - auc: 0.9757 - val_loss: 0.5213 - val_auc_01: 0.6920 - val_auc: 0.8049\n",
      "Epoch 183/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1169 - auc_01: 0.9278 - auc: 0.9799 - val_loss: 0.5191 - val_auc_01: 0.6915 - val_auc: 0.8137\n",
      "Epoch 184/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1188 - auc_01: 0.9230 - auc: 0.9800 - val_loss: 0.5141 - val_auc_01: 0.6972 - val_auc: 0.8092\n",
      "Epoch 185/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1175 - auc_01: 0.9379 - auc: 0.9781 - val_loss: 0.5066 - val_auc_01: 0.6951 - val_auc: 0.8162\n",
      "Epoch 186/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1135 - auc_01: 0.9265 - auc: 0.9814 - val_loss: 0.5453 - val_auc_01: 0.6943 - val_auc: 0.8066\n",
      "Epoch 187/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1184 - auc_01: 0.9282 - auc: 0.9787 - val_loss: 0.5102 - val_auc_01: 0.7072 - val_auc: 0.8135\n",
      "Epoch 188/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1126 - auc_01: 0.9280 - auc: 0.9810 - val_loss: 0.5259 - val_auc_01: 0.6925 - val_auc: 0.8067\n",
      "Epoch 189/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1181 - auc_01: 0.9241 - auc: 0.9801 - val_loss: 0.5058 - val_auc_01: 0.6862 - val_auc: 0.8133\n",
      "Epoch 190/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1120 - auc_01: 0.9317 - auc: 0.9812 - val_loss: 0.5448 - val_auc_01: 0.6892 - val_auc: 0.8011\n",
      "Epoch 191/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1176 - auc_01: 0.9319 - auc: 0.9803 - val_loss: 0.5545 - val_auc_01: 0.6913 - val_auc: 0.8015\n",
      "Epoch 192/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1138 - auc_01: 0.9369 - auc: 0.9829 - val_loss: 0.5396 - val_auc_01: 0.6895 - val_auc: 0.8032\n",
      "Epoch 193/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1158 - auc_01: 0.9208 - auc: 0.9811 - val_loss: 0.5227 - val_auc_01: 0.6896 - val_auc: 0.8094\n",
      "Epoch 194/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1116 - auc_01: 0.9345 - auc: 0.9822 - val_loss: 0.5289 - val_auc_01: 0.7019 - val_auc: 0.8111\n",
      "Epoch 195/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1130 - auc_01: 0.9334 - auc: 0.9820 - val_loss: 0.5299 - val_auc_01: 0.6995 - val_auc: 0.8094\n",
      "Epoch 196/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1066 - auc_01: 0.9398 - auc: 0.9832 - val_loss: 0.5360 - val_auc_01: 0.6967 - val_auc: 0.8057\n",
      "Epoch 197/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1060 - auc_01: 0.9406 - auc: 0.9841 - val_loss: 0.5301 - val_auc_01: 0.6907 - val_auc: 0.8045\n",
      "Epoch 198/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1088 - auc_01: 0.9376 - auc: 0.9819 - val_loss: 0.5477 - val_auc_01: 0.6915 - val_auc: 0.8071\n",
      "Epoch 199/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1147 - auc_01: 0.9289 - auc: 0.9803 - val_loss: 0.5139 - val_auc_01: 0.6915 - val_auc: 0.8106\n",
      "Epoch 200/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1065 - auc_01: 0.9404 - auc: 0.9840 - val_loss: 0.5142 - val_auc_01: 0.6910 - val_auc: 0.8146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 36). These functions will not be directly callable after loading.\n",
      "2024-12-04 23:02:51.949769: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2024-12-04 23:02:51.949797: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2024-12-04 23:02:51.950801: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmp5hibh_6n\n",
      "2024-12-04 23:02:51.959945: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-12-04 23:02:51.959957: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmp5hibh_6n\n",
      "2024-12-04 23:02:51.987309: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2024-12-04 23:02:51.995711: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2024-12-04 23:02:52.245475: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmp5hibh_6n\n",
      "2024-12-04 23:02:52.304302: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 353666 microseconds.\n",
      "2024-12-04 23:02:52.455376: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(1500x1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 23:02:59.628083: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "86/86 [==============================] - 6s 29ms/step - loss: 0.4939 - auc_01: 0.5010 - auc: 0.4966 - val_loss: 0.4420 - val_auc_01: 0.5058 - val_auc: 0.4855\n",
      "Epoch 2/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4514 - auc_01: 0.5151 - auc: 0.5203 - val_loss: 0.4454 - val_auc_01: 0.5044 - val_auc: 0.4818\n",
      "Epoch 3/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4528 - auc_01: 0.5108 - auc: 0.5031 - val_loss: 0.4400 - val_auc_01: 0.4956 - val_auc: 0.4825\n",
      "Epoch 4/200\n",
      "86/86 [==============================] - 2s 21ms/step - loss: 0.4519 - auc_01: 0.5062 - auc: 0.4987 - val_loss: 0.4396 - val_auc_01: 0.4917 - val_auc: 0.4779\n",
      "Epoch 5/200\n",
      "86/86 [==============================] - 2s 22ms/step - loss: 0.4513 - auc_01: 0.5091 - auc: 0.5125 - val_loss: 0.4396 - val_auc_01: 0.4976 - val_auc: 0.4762\n",
      "Epoch 6/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4515 - auc_01: 0.5076 - auc: 0.5075 - val_loss: 0.4397 - val_auc_01: 0.4983 - val_auc: 0.4810\n",
      "Epoch 7/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4510 - auc_01: 0.5106 - auc: 0.5212 - val_loss: 0.4396 - val_auc_01: 0.4987 - val_auc: 0.4822\n",
      "Epoch 8/200\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.4478 - auc_01: 0.5191 - auc: 0.5319 - val_loss: 0.4408 - val_auc_01: 0.4997 - val_auc: 0.4873\n",
      "Epoch 9/200\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.4491 - auc_01: 0.5166 - auc: 0.5307 - val_loss: 0.4400 - val_auc_01: 0.4979 - val_auc: 0.4895\n",
      "Epoch 10/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4461 - auc_01: 0.5277 - auc: 0.5488 - val_loss: 0.4419 - val_auc_01: 0.5050 - val_auc: 0.4869\n",
      "Epoch 11/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4462 - auc_01: 0.5283 - auc: 0.5385 - val_loss: 0.4414 - val_auc_01: 0.5094 - val_auc: 0.4925\n",
      "Epoch 12/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4444 - auc_01: 0.5379 - auc: 0.5417 - val_loss: 0.4424 - val_auc_01: 0.5010 - val_auc: 0.5029\n",
      "Epoch 13/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4447 - auc_01: 0.5365 - auc: 0.5468 - val_loss: 0.4395 - val_auc_01: 0.5076 - val_auc: 0.5009\n",
      "Epoch 14/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4412 - auc_01: 0.5340 - auc: 0.5576 - val_loss: 0.4395 - val_auc_01: 0.5063 - val_auc: 0.5132\n",
      "Epoch 15/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4374 - auc_01: 0.5429 - auc: 0.5801 - val_loss: 0.4414 - val_auc_01: 0.5141 - val_auc: 0.5338\n",
      "Epoch 16/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4357 - auc_01: 0.5455 - auc: 0.5820 - val_loss: 0.4355 - val_auc_01: 0.5134 - val_auc: 0.5430\n",
      "Epoch 17/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4306 - auc_01: 0.5487 - auc: 0.6145 - val_loss: 0.4372 - val_auc_01: 0.5111 - val_auc: 0.5225\n",
      "Epoch 18/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4275 - auc_01: 0.5566 - auc: 0.6134 - val_loss: 0.4334 - val_auc_01: 0.5191 - val_auc: 0.5854\n",
      "Epoch 19/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4249 - auc_01: 0.5573 - auc: 0.6405 - val_loss: 0.4295 - val_auc_01: 0.5218 - val_auc: 0.6106\n",
      "Epoch 20/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4162 - auc_01: 0.5711 - auc: 0.6588 - val_loss: 0.4240 - val_auc_01: 0.5385 - val_auc: 0.6302\n",
      "Epoch 21/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.4175 - auc_01: 0.5670 - auc: 0.6618 - val_loss: 0.4252 - val_auc_01: 0.5358 - val_auc: 0.6356\n",
      "Epoch 22/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4127 - auc_01: 0.5688 - auc: 0.6882 - val_loss: 0.4188 - val_auc_01: 0.5430 - val_auc: 0.6678\n",
      "Epoch 23/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4051 - auc_01: 0.5737 - auc: 0.7019 - val_loss: 0.4150 - val_auc_01: 0.5329 - val_auc: 0.6867\n",
      "Epoch 24/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.4057 - auc_01: 0.5846 - auc: 0.7080 - val_loss: 0.4139 - val_auc_01: 0.5385 - val_auc: 0.7059\n",
      "Epoch 25/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3915 - auc_01: 0.5852 - auc: 0.7471 - val_loss: 0.4046 - val_auc_01: 0.5878 - val_auc: 0.7166\n",
      "Epoch 26/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3845 - auc_01: 0.6126 - auc: 0.7538 - val_loss: 0.4014 - val_auc_01: 0.5667 - val_auc: 0.7255\n",
      "Epoch 27/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.3816 - auc_01: 0.6234 - auc: 0.7651 - val_loss: 0.4022 - val_auc_01: 0.5983 - val_auc: 0.7177\n",
      "Epoch 28/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.3730 - auc_01: 0.6260 - auc: 0.7769 - val_loss: 0.3940 - val_auc_01: 0.5956 - val_auc: 0.7321\n",
      "Epoch 29/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3607 - auc_01: 0.6416 - auc: 0.7949 - val_loss: 0.3897 - val_auc_01: 0.6041 - val_auc: 0.7434\n",
      "Epoch 30/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3605 - auc_01: 0.6471 - auc: 0.7973 - val_loss: 0.3960 - val_auc_01: 0.6004 - val_auc: 0.7381\n",
      "Epoch 31/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.3508 - auc_01: 0.6655 - auc: 0.8108 - val_loss: 0.3898 - val_auc_01: 0.6121 - val_auc: 0.7423\n",
      "Epoch 32/200\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.3455 - auc_01: 0.6736 - auc: 0.8180 - val_loss: 0.3897 - val_auc_01: 0.6211 - val_auc: 0.7401\n",
      "Epoch 33/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3388 - auc_01: 0.6785 - auc: 0.8220 - val_loss: 0.3869 - val_auc_01: 0.6270 - val_auc: 0.7483\n",
      "Epoch 34/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3371 - auc_01: 0.6795 - auc: 0.8198 - val_loss: 0.3866 - val_auc_01: 0.6298 - val_auc: 0.7579\n",
      "Epoch 35/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.3274 - auc_01: 0.7002 - auc: 0.8379 - val_loss: 0.3875 - val_auc_01: 0.6368 - val_auc: 0.7552\n",
      "Epoch 36/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3298 - auc_01: 0.6863 - auc: 0.8367 - val_loss: 0.3824 - val_auc_01: 0.6294 - val_auc: 0.7657\n",
      "Epoch 37/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3167 - auc_01: 0.7120 - auc: 0.8441 - val_loss: 0.3835 - val_auc_01: 0.6437 - val_auc: 0.7566\n",
      "Epoch 38/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3147 - auc_01: 0.7032 - auc: 0.8468 - val_loss: 0.3840 - val_auc_01: 0.6357 - val_auc: 0.7645\n",
      "Epoch 39/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3148 - auc_01: 0.7087 - auc: 0.8500 - val_loss: 0.3873 - val_auc_01: 0.6371 - val_auc: 0.7704\n",
      "Epoch 40/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3055 - auc_01: 0.7182 - auc: 0.8591 - val_loss: 0.4041 - val_auc_01: 0.6313 - val_auc: 0.7544\n",
      "Epoch 41/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2987 - auc_01: 0.7143 - auc: 0.8675 - val_loss: 0.3818 - val_auc_01: 0.6357 - val_auc: 0.7694\n",
      "Epoch 42/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2982 - auc_01: 0.7272 - auc: 0.8696 - val_loss: 0.3861 - val_auc_01: 0.6384 - val_auc: 0.7734\n",
      "Epoch 43/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2876 - auc_01: 0.7357 - auc: 0.8788 - val_loss: 0.3900 - val_auc_01: 0.6447 - val_auc: 0.7700\n",
      "Epoch 44/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2818 - auc_01: 0.7470 - auc: 0.8835 - val_loss: 0.3967 - val_auc_01: 0.6370 - val_auc: 0.7649\n",
      "Epoch 45/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2830 - auc_01: 0.7467 - auc: 0.8814 - val_loss: 0.3893 - val_auc_01: 0.6487 - val_auc: 0.7773\n",
      "Epoch 46/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2804 - auc_01: 0.7422 - auc: 0.8820 - val_loss: 0.3860 - val_auc_01: 0.6410 - val_auc: 0.7819\n",
      "Epoch 47/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2776 - auc_01: 0.7497 - auc: 0.8864 - val_loss: 0.3972 - val_auc_01: 0.6352 - val_auc: 0.7763\n",
      "Epoch 48/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2725 - auc_01: 0.7621 - auc: 0.8934 - val_loss: 0.4068 - val_auc_01: 0.6397 - val_auc: 0.7751\n",
      "Epoch 49/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2731 - auc_01: 0.7603 - auc: 0.8883 - val_loss: 0.4024 - val_auc_01: 0.6405 - val_auc: 0.7661\n",
      "Epoch 50/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2706 - auc_01: 0.7526 - auc: 0.8910 - val_loss: 0.4025 - val_auc_01: 0.6451 - val_auc: 0.7728\n",
      "Epoch 51/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2614 - auc_01: 0.7640 - auc: 0.8965 - val_loss: 0.3920 - val_auc_01: 0.6444 - val_auc: 0.7809\n",
      "Epoch 52/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2595 - auc_01: 0.7690 - auc: 0.9022 - val_loss: 0.3904 - val_auc_01: 0.6467 - val_auc: 0.7839\n",
      "Epoch 53/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2552 - auc_01: 0.7771 - auc: 0.9062 - val_loss: 0.3936 - val_auc_01: 0.6439 - val_auc: 0.7890\n",
      "Epoch 54/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2523 - auc_01: 0.7786 - auc: 0.9087 - val_loss: 0.4008 - val_auc_01: 0.6416 - val_auc: 0.7834\n",
      "Epoch 55/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2594 - auc_01: 0.7608 - auc: 0.9040 - val_loss: 0.3943 - val_auc_01: 0.6485 - val_auc: 0.7872\n",
      "Epoch 56/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2558 - auc_01: 0.7689 - auc: 0.9093 - val_loss: 0.3989 - val_auc_01: 0.6501 - val_auc: 0.7854\n",
      "Epoch 57/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2521 - auc_01: 0.7669 - auc: 0.9072 - val_loss: 0.3942 - val_auc_01: 0.6457 - val_auc: 0.7925\n",
      "Epoch 58/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2522 - auc_01: 0.7794 - auc: 0.9070 - val_loss: 0.3939 - val_auc_01: 0.6481 - val_auc: 0.7935\n",
      "Epoch 59/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2438 - auc_01: 0.7812 - auc: 0.9146 - val_loss: 0.4004 - val_auc_01: 0.6460 - val_auc: 0.7893\n",
      "Epoch 60/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2400 - auc_01: 0.7889 - auc: 0.9173 - val_loss: 0.4214 - val_auc_01: 0.6427 - val_auc: 0.7803\n",
      "Epoch 61/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2366 - auc_01: 0.7982 - auc: 0.9183 - val_loss: 0.4104 - val_auc_01: 0.6513 - val_auc: 0.7855\n",
      "Epoch 62/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2371 - auc_01: 0.7902 - auc: 0.9159 - val_loss: 0.4067 - val_auc_01: 0.6533 - val_auc: 0.7970\n",
      "Epoch 63/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2408 - auc_01: 0.7959 - auc: 0.9154 - val_loss: 0.4029 - val_auc_01: 0.6485 - val_auc: 0.7971\n",
      "Epoch 64/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2316 - auc_01: 0.8031 - auc: 0.9247 - val_loss: 0.4150 - val_auc_01: 0.6577 - val_auc: 0.7878\n",
      "Epoch 65/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2318 - auc_01: 0.7986 - auc: 0.9221 - val_loss: 0.4078 - val_auc_01: 0.6655 - val_auc: 0.7925\n",
      "Epoch 66/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2273 - auc_01: 0.8033 - auc: 0.9279 - val_loss: 0.4074 - val_auc_01: 0.6577 - val_auc: 0.7953\n",
      "Epoch 67/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2233 - auc_01: 0.8131 - auc: 0.9308 - val_loss: 0.4279 - val_auc_01: 0.6587 - val_auc: 0.7809\n",
      "Epoch 68/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2204 - auc_01: 0.8191 - auc: 0.9312 - val_loss: 0.4337 - val_auc_01: 0.6609 - val_auc: 0.7859\n",
      "Epoch 69/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2240 - auc_01: 0.8060 - auc: 0.9261 - val_loss: 0.4122 - val_auc_01: 0.6644 - val_auc: 0.7950\n",
      "Epoch 70/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2231 - auc_01: 0.8000 - auc: 0.9281 - val_loss: 0.4080 - val_auc_01: 0.6677 - val_auc: 0.7958\n",
      "Epoch 71/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2279 - auc_01: 0.8015 - auc: 0.9256 - val_loss: 0.4103 - val_auc_01: 0.6578 - val_auc: 0.7977\n",
      "Epoch 72/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2223 - auc_01: 0.8187 - auc: 0.9288 - val_loss: 0.4191 - val_auc_01: 0.6624 - val_auc: 0.7950\n",
      "Epoch 73/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2127 - auc_01: 0.8188 - auc: 0.9368 - val_loss: 0.4306 - val_auc_01: 0.6694 - val_auc: 0.7954\n",
      "Epoch 74/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2145 - auc_01: 0.8227 - auc: 0.9337 - val_loss: 0.4108 - val_auc_01: 0.6653 - val_auc: 0.8037\n",
      "Epoch 75/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2085 - auc_01: 0.8240 - auc: 0.9364 - val_loss: 0.4249 - val_auc_01: 0.6669 - val_auc: 0.7967\n",
      "Epoch 76/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2068 - auc_01: 0.8268 - auc: 0.9381 - val_loss: 0.4092 - val_auc_01: 0.6596 - val_auc: 0.8038\n",
      "Epoch 77/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2099 - auc_01: 0.8245 - auc: 0.9381 - val_loss: 0.4253 - val_auc_01: 0.6714 - val_auc: 0.7910\n",
      "Epoch 78/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2091 - auc_01: 0.8227 - auc: 0.9390 - val_loss: 0.4516 - val_auc_01: 0.6652 - val_auc: 0.7899\n",
      "Epoch 79/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2068 - auc_01: 0.8223 - auc: 0.9379 - val_loss: 0.4143 - val_auc_01: 0.6753 - val_auc: 0.8007\n",
      "Epoch 80/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2007 - auc_01: 0.8345 - auc: 0.9402 - val_loss: 0.4165 - val_auc_01: 0.6602 - val_auc: 0.8084\n",
      "Epoch 81/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1919 - auc_01: 0.8453 - auc: 0.9463 - val_loss: 0.4245 - val_auc_01: 0.6573 - val_auc: 0.7973\n",
      "Epoch 82/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1995 - auc_01: 0.8352 - auc: 0.9421 - val_loss: 0.4247 - val_auc_01: 0.6734 - val_auc: 0.8026\n",
      "Epoch 83/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2021 - auc_01: 0.8340 - auc: 0.9416 - val_loss: 0.4249 - val_auc_01: 0.6716 - val_auc: 0.8007\n",
      "Epoch 84/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1991 - auc_01: 0.8428 - auc: 0.9434 - val_loss: 0.4319 - val_auc_01: 0.6688 - val_auc: 0.8018\n",
      "Epoch 85/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1922 - auc_01: 0.8392 - auc: 0.9481 - val_loss: 0.4412 - val_auc_01: 0.6653 - val_auc: 0.7997\n",
      "Epoch 86/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1989 - auc_01: 0.8371 - auc: 0.9448 - val_loss: 0.4412 - val_auc_01: 0.6716 - val_auc: 0.7971\n",
      "Epoch 87/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1921 - auc_01: 0.8542 - auc: 0.9440 - val_loss: 0.4378 - val_auc_01: 0.6699 - val_auc: 0.7985\n",
      "Epoch 88/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1903 - auc_01: 0.8388 - auc: 0.9480 - val_loss: 0.4316 - val_auc_01: 0.6709 - val_auc: 0.8026\n",
      "Epoch 89/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1893 - auc_01: 0.8547 - auc: 0.9493 - val_loss: 0.4226 - val_auc_01: 0.6753 - val_auc: 0.8045\n",
      "Epoch 90/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1891 - auc_01: 0.8473 - auc: 0.9480 - val_loss: 0.4386 - val_auc_01: 0.6781 - val_auc: 0.8024\n",
      "Epoch 91/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1885 - auc_01: 0.8509 - auc: 0.9516 - val_loss: 0.4200 - val_auc_01: 0.6828 - val_auc: 0.8058\n",
      "Epoch 92/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1774 - auc_01: 0.8745 - auc: 0.9535 - val_loss: 0.4278 - val_auc_01: 0.6741 - val_auc: 0.8056\n",
      "Epoch 93/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1851 - auc_01: 0.8504 - auc: 0.9501 - val_loss: 0.4446 - val_auc_01: 0.6732 - val_auc: 0.7937\n",
      "Epoch 94/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1807 - auc_01: 0.8590 - auc: 0.9545 - val_loss: 0.4472 - val_auc_01: 0.6752 - val_auc: 0.7988\n",
      "Epoch 95/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1790 - auc_01: 0.8694 - auc: 0.9543 - val_loss: 0.4336 - val_auc_01: 0.6801 - val_auc: 0.8119\n",
      "Epoch 96/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1838 - auc_01: 0.8554 - auc: 0.9520 - val_loss: 0.4374 - val_auc_01: 0.6875 - val_auc: 0.8075\n",
      "Epoch 97/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1737 - auc_01: 0.8662 - auc: 0.9561 - val_loss: 0.4406 - val_auc_01: 0.6794 - val_auc: 0.8045\n",
      "Epoch 98/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1825 - auc_01: 0.8555 - auc: 0.9526 - val_loss: 0.4389 - val_auc_01: 0.6754 - val_auc: 0.8038\n",
      "Epoch 99/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1834 - auc_01: 0.8491 - auc: 0.9543 - val_loss: 0.4362 - val_auc_01: 0.6731 - val_auc: 0.8083\n",
      "Epoch 100/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1644 - auc_01: 0.8750 - auc: 0.9618 - val_loss: 0.4351 - val_auc_01: 0.6796 - val_auc: 0.8041\n",
      "Epoch 101/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1820 - auc_01: 0.8632 - auc: 0.9547 - val_loss: 0.4381 - val_auc_01: 0.6828 - val_auc: 0.8065\n",
      "Epoch 102/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1712 - auc_01: 0.8727 - auc: 0.9573 - val_loss: 0.4439 - val_auc_01: 0.6713 - val_auc: 0.8100\n",
      "Epoch 103/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1632 - auc_01: 0.8755 - auc: 0.9629 - val_loss: 0.4371 - val_auc_01: 0.6702 - val_auc: 0.8118\n",
      "Epoch 104/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1663 - auc_01: 0.8746 - auc: 0.9612 - val_loss: 0.4507 - val_auc_01: 0.6735 - val_auc: 0.8105\n",
      "Epoch 105/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1708 - auc_01: 0.8745 - auc: 0.9562 - val_loss: 0.4597 - val_auc_01: 0.6726 - val_auc: 0.8083\n",
      "Epoch 106/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1715 - auc_01: 0.8729 - auc: 0.9596 - val_loss: 0.4630 - val_auc_01: 0.6770 - val_auc: 0.8044\n",
      "Epoch 107/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1603 - auc_01: 0.8808 - auc: 0.9643 - val_loss: 0.4575 - val_auc_01: 0.6737 - val_auc: 0.8096\n",
      "Epoch 108/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1660 - auc_01: 0.8753 - auc: 0.9609 - val_loss: 0.4559 - val_auc_01: 0.6729 - val_auc: 0.8025\n",
      "Epoch 109/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1619 - auc_01: 0.8854 - auc: 0.9631 - val_loss: 0.4555 - val_auc_01: 0.6845 - val_auc: 0.8092\n",
      "Epoch 110/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1641 - auc_01: 0.8763 - auc: 0.9611 - val_loss: 0.4481 - val_auc_01: 0.6795 - val_auc: 0.8104\n",
      "Epoch 111/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1642 - auc_01: 0.8791 - auc: 0.9629 - val_loss: 0.4660 - val_auc_01: 0.6678 - val_auc: 0.8035\n",
      "Epoch 112/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1574 - auc_01: 0.8872 - auc: 0.9649 - val_loss: 0.4477 - val_auc_01: 0.6710 - val_auc: 0.8071\n",
      "Epoch 113/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1657 - auc_01: 0.8730 - auc: 0.9594 - val_loss: 0.4580 - val_auc_01: 0.6706 - val_auc: 0.8055\n",
      "Epoch 114/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1634 - auc_01: 0.8832 - auc: 0.9634 - val_loss: 0.4696 - val_auc_01: 0.6719 - val_auc: 0.7946\n",
      "Epoch 115/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1642 - auc_01: 0.8749 - auc: 0.9651 - val_loss: 0.4651 - val_auc_01: 0.6714 - val_auc: 0.8084\n",
      "Epoch 116/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1646 - auc_01: 0.8710 - auc: 0.9609 - val_loss: 0.4534 - val_auc_01: 0.6673 - val_auc: 0.8065\n",
      "Epoch 117/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1529 - auc_01: 0.8953 - auc: 0.9675 - val_loss: 0.4748 - val_auc_01: 0.6673 - val_auc: 0.7963\n",
      "Epoch 118/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1627 - auc_01: 0.8766 - auc: 0.9628 - val_loss: 0.4591 - val_auc_01: 0.6790 - val_auc: 0.8057\n",
      "Epoch 119/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1553 - auc_01: 0.8868 - auc: 0.9650 - val_loss: 0.4481 - val_auc_01: 0.6788 - val_auc: 0.8073\n",
      "Epoch 120/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1523 - auc_01: 0.8936 - auc: 0.9677 - val_loss: 0.4749 - val_auc_01: 0.6759 - val_auc: 0.8089\n",
      "Epoch 121/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1591 - auc_01: 0.8869 - auc: 0.9654 - val_loss: 0.4657 - val_auc_01: 0.6748 - val_auc: 0.8050\n",
      "Epoch 122/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1531 - auc_01: 0.8876 - auc: 0.9670 - val_loss: 0.4703 - val_auc_01: 0.6644 - val_auc: 0.8062\n",
      "Epoch 123/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1525 - auc_01: 0.8954 - auc: 0.9654 - val_loss: 0.4645 - val_auc_01: 0.6681 - val_auc: 0.8099\n",
      "Epoch 124/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1430 - auc_01: 0.9019 - auc: 0.9702 - val_loss: 0.4889 - val_auc_01: 0.6753 - val_auc: 0.7974\n",
      "Epoch 125/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1519 - auc_01: 0.8967 - auc: 0.9690 - val_loss: 0.4664 - val_auc_01: 0.6764 - val_auc: 0.8030\n",
      "Epoch 126/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1473 - auc_01: 0.9010 - auc: 0.9702 - val_loss: 0.4521 - val_auc_01: 0.6759 - val_auc: 0.8165\n",
      "Epoch 127/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1453 - auc_01: 0.9010 - auc: 0.9721 - val_loss: 0.4596 - val_auc_01: 0.6752 - val_auc: 0.8105\n",
      "Epoch 128/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1504 - auc_01: 0.8947 - auc: 0.9680 - val_loss: 0.4719 - val_auc_01: 0.6695 - val_auc: 0.8104\n",
      "Epoch 129/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1472 - auc_01: 0.8907 - auc: 0.9694 - val_loss: 0.4857 - val_auc_01: 0.6713 - val_auc: 0.7990\n",
      "Epoch 130/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1396 - auc_01: 0.9111 - auc: 0.9725 - val_loss: 0.4816 - val_auc_01: 0.6697 - val_auc: 0.8054\n",
      "Epoch 131/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1444 - auc_01: 0.8997 - auc: 0.9703 - val_loss: 0.4905 - val_auc_01: 0.6795 - val_auc: 0.8009\n",
      "Epoch 132/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1398 - auc_01: 0.9039 - auc: 0.9745 - val_loss: 0.4877 - val_auc_01: 0.6769 - val_auc: 0.8016\n",
      "Epoch 133/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1389 - auc_01: 0.9098 - auc: 0.9730 - val_loss: 0.5101 - val_auc_01: 0.6761 - val_auc: 0.7991\n",
      "Epoch 134/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1417 - auc_01: 0.9020 - auc: 0.9686 - val_loss: 0.4763 - val_auc_01: 0.6753 - val_auc: 0.8024\n",
      "Epoch 135/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1420 - auc_01: 0.9048 - auc: 0.9733 - val_loss: 0.5041 - val_auc_01: 0.6750 - val_auc: 0.8044\n",
      "Epoch 136/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1505 - auc_01: 0.8950 - auc: 0.9675 - val_loss: 0.4695 - val_auc_01: 0.6794 - val_auc: 0.8133\n",
      "Epoch 137/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1473 - auc_01: 0.8947 - auc: 0.9698 - val_loss: 0.4934 - val_auc_01: 0.6741 - val_auc: 0.8105\n",
      "Epoch 138/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1423 - auc_01: 0.8987 - auc: 0.9720 - val_loss: 0.4937 - val_auc_01: 0.6654 - val_auc: 0.8002\n",
      "Epoch 139/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1420 - auc_01: 0.9074 - auc: 0.9735 - val_loss: 0.4794 - val_auc_01: 0.6711 - val_auc: 0.8059\n",
      "Epoch 140/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1360 - auc_01: 0.9132 - auc: 0.9734 - val_loss: 0.5211 - val_auc_01: 0.6750 - val_auc: 0.7989\n",
      "Epoch 141/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1319 - auc_01: 0.9114 - auc: 0.9748 - val_loss: 0.4904 - val_auc_01: 0.6696 - val_auc: 0.8001\n",
      "Epoch 142/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1363 - auc_01: 0.9022 - auc: 0.9753 - val_loss: 0.4981 - val_auc_01: 0.6792 - val_auc: 0.8026\n",
      "Epoch 143/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1424 - auc_01: 0.9020 - auc: 0.9721 - val_loss: 0.4872 - val_auc_01: 0.6573 - val_auc: 0.8081\n",
      "Epoch 144/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1367 - auc_01: 0.9079 - auc: 0.9735 - val_loss: 0.5176 - val_auc_01: 0.6710 - val_auc: 0.7957\n",
      "Epoch 145/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1370 - auc_01: 0.9081 - auc: 0.9750 - val_loss: 0.5105 - val_auc_01: 0.6684 - val_auc: 0.8041\n",
      "Epoch 146/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1285 - auc_01: 0.9200 - auc: 0.9782 - val_loss: 0.5132 - val_auc_01: 0.6752 - val_auc: 0.7994\n",
      "Epoch 147/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1273 - auc_01: 0.9194 - auc: 0.9778 - val_loss: 0.4916 - val_auc_01: 0.6594 - val_auc: 0.8084\n",
      "Epoch 148/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1274 - auc_01: 0.9155 - auc: 0.9774 - val_loss: 0.5097 - val_auc_01: 0.6631 - val_auc: 0.7979\n",
      "Epoch 149/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1293 - auc_01: 0.9175 - auc: 0.9781 - val_loss: 0.5162 - val_auc_01: 0.6719 - val_auc: 0.8044\n",
      "Epoch 150/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1366 - auc_01: 0.9029 - auc: 0.9751 - val_loss: 0.5283 - val_auc_01: 0.6740 - val_auc: 0.7894\n",
      "Epoch 151/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1338 - auc_01: 0.9141 - auc: 0.9749 - val_loss: 0.4884 - val_auc_01: 0.6692 - val_auc: 0.8115\n",
      "Epoch 152/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1310 - auc_01: 0.9197 - auc: 0.9749 - val_loss: 0.5113 - val_auc_01: 0.6699 - val_auc: 0.8049\n",
      "Epoch 153/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1311 - auc_01: 0.9199 - auc: 0.9755 - val_loss: 0.5070 - val_auc_01: 0.6586 - val_auc: 0.8031\n",
      "Epoch 154/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1300 - auc_01: 0.9106 - auc: 0.9762 - val_loss: 0.5128 - val_auc_01: 0.6740 - val_auc: 0.8058\n",
      "Epoch 155/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1334 - auc_01: 0.9110 - auc: 0.9755 - val_loss: 0.5150 - val_auc_01: 0.6754 - val_auc: 0.8013\n",
      "Epoch 156/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1288 - auc_01: 0.9199 - auc: 0.9776 - val_loss: 0.4951 - val_auc_01: 0.6722 - val_auc: 0.8038\n",
      "Epoch 157/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1282 - auc_01: 0.9164 - auc: 0.9773 - val_loss: 0.5169 - val_auc_01: 0.6765 - val_auc: 0.8065\n",
      "Epoch 158/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1268 - auc_01: 0.9194 - auc: 0.9777 - val_loss: 0.5139 - val_auc_01: 0.6766 - val_auc: 0.8061\n",
      "Epoch 159/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1191 - auc_01: 0.9284 - auc: 0.9802 - val_loss: 0.4952 - val_auc_01: 0.6677 - val_auc: 0.8099\n",
      "Epoch 160/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1302 - auc_01: 0.9108 - auc: 0.9758 - val_loss: 0.5149 - val_auc_01: 0.6762 - val_auc: 0.8139\n",
      "Epoch 161/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1270 - auc_01: 0.9179 - auc: 0.9780 - val_loss: 0.5301 - val_auc_01: 0.6750 - val_auc: 0.8122\n",
      "Epoch 162/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1250 - auc_01: 0.9171 - auc: 0.9777 - val_loss: 0.5125 - val_auc_01: 0.6659 - val_auc: 0.8097\n",
      "Epoch 163/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1223 - auc_01: 0.9198 - auc: 0.9796 - val_loss: 0.5373 - val_auc_01: 0.6759 - val_auc: 0.8019\n",
      "Epoch 164/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1212 - auc_01: 0.9183 - auc: 0.9807 - val_loss: 0.5116 - val_auc_01: 0.6685 - val_auc: 0.8025\n",
      "Epoch 165/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1228 - auc_01: 0.9257 - auc: 0.9795 - val_loss: 0.4991 - val_auc_01: 0.6684 - val_auc: 0.8148\n",
      "Epoch 166/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1274 - auc_01: 0.9143 - auc: 0.9773 - val_loss: 0.5158 - val_auc_01: 0.6722 - val_auc: 0.8028\n",
      "Epoch 167/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1175 - auc_01: 0.9321 - auc: 0.9814 - val_loss: 0.5092 - val_auc_01: 0.6738 - val_auc: 0.8083\n",
      "Epoch 168/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1145 - auc_01: 0.9331 - auc: 0.9826 - val_loss: 0.5599 - val_auc_01: 0.6699 - val_auc: 0.7892\n",
      "Epoch 169/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1215 - auc_01: 0.9269 - auc: 0.9813 - val_loss: 0.5340 - val_auc_01: 0.6734 - val_auc: 0.8070\n",
      "Epoch 170/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1214 - auc_01: 0.9301 - auc: 0.9791 - val_loss: 0.5298 - val_auc_01: 0.6705 - val_auc: 0.8017\n",
      "Epoch 171/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1166 - auc_01: 0.9271 - auc: 0.9807 - val_loss: 0.5572 - val_auc_01: 0.6712 - val_auc: 0.7962\n",
      "Epoch 172/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1173 - auc_01: 0.9290 - auc: 0.9796 - val_loss: 0.5330 - val_auc_01: 0.6705 - val_auc: 0.8058\n",
      "Epoch 173/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1281 - auc_01: 0.9188 - auc: 0.9785 - val_loss: 0.5342 - val_auc_01: 0.6655 - val_auc: 0.8014\n",
      "Epoch 174/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1189 - auc_01: 0.9323 - auc: 0.9819 - val_loss: 0.5095 - val_auc_01: 0.6683 - val_auc: 0.8116\n",
      "Epoch 175/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1195 - auc_01: 0.9269 - auc: 0.9798 - val_loss: 0.5659 - val_auc_01: 0.6593 - val_auc: 0.7993\n",
      "Epoch 176/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1188 - auc_01: 0.9270 - auc: 0.9815 - val_loss: 0.5336 - val_auc_01: 0.6627 - val_auc: 0.8112\n",
      "Epoch 177/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1230 - auc_01: 0.9156 - auc: 0.9788 - val_loss: 0.5409 - val_auc_01: 0.6732 - val_auc: 0.7999\n",
      "Epoch 178/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1069 - auc_01: 0.9415 - auc: 0.9852 - val_loss: 0.5521 - val_auc_01: 0.6688 - val_auc: 0.8006\n",
      "Epoch 179/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1159 - auc_01: 0.9272 - auc: 0.9811 - val_loss: 0.5658 - val_auc_01: 0.6693 - val_auc: 0.8025\n",
      "Epoch 180/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1185 - auc_01: 0.9308 - auc: 0.9796 - val_loss: 0.5335 - val_auc_01: 0.6624 - val_auc: 0.8017\n",
      "Epoch 181/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1161 - auc_01: 0.9343 - auc: 0.9828 - val_loss: 0.5363 - val_auc_01: 0.6700 - val_auc: 0.8099\n",
      "Epoch 182/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1151 - auc_01: 0.9291 - auc: 0.9811 - val_loss: 0.5230 - val_auc_01: 0.6760 - val_auc: 0.8095\n",
      "Epoch 183/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1127 - auc_01: 0.9326 - auc: 0.9826 - val_loss: 0.5297 - val_auc_01: 0.6764 - val_auc: 0.8100\n",
      "Epoch 184/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1161 - auc_01: 0.9269 - auc: 0.9814 - val_loss: 0.5606 - val_auc_01: 0.6731 - val_auc: 0.7971\n",
      "Epoch 185/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1124 - auc_01: 0.9356 - auc: 0.9820 - val_loss: 0.5533 - val_auc_01: 0.6770 - val_auc: 0.8006\n",
      "Epoch 186/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1129 - auc_01: 0.9359 - auc: 0.9812 - val_loss: 0.5642 - val_auc_01: 0.6696 - val_auc: 0.7974\n",
      "Epoch 187/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1074 - auc_01: 0.9387 - auc: 0.9845 - val_loss: 0.5614 - val_auc_01: 0.6756 - val_auc: 0.7985\n",
      "Epoch 188/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1165 - auc_01: 0.9251 - auc: 0.9798 - val_loss: 0.5476 - val_auc_01: 0.6636 - val_auc: 0.7965\n",
      "Epoch 189/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1112 - auc_01: 0.9325 - auc: 0.9829 - val_loss: 0.5283 - val_auc_01: 0.6717 - val_auc: 0.8043\n",
      "Epoch 190/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1134 - auc_01: 0.9320 - auc: 0.9834 - val_loss: 0.5295 - val_auc_01: 0.6660 - val_auc: 0.8081\n",
      "Epoch 191/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1111 - auc_01: 0.9355 - auc: 0.9829 - val_loss: 0.5597 - val_auc_01: 0.6668 - val_auc: 0.7983\n",
      "Epoch 192/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1103 - auc_01: 0.9376 - auc: 0.9830 - val_loss: 0.5511 - val_auc_01: 0.6709 - val_auc: 0.8026\n",
      "Epoch 193/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1102 - auc_01: 0.9342 - auc: 0.9835 - val_loss: 0.5646 - val_auc_01: 0.6640 - val_auc: 0.7987\n",
      "Epoch 194/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1074 - auc_01: 0.9407 - auc: 0.9833 - val_loss: 0.5497 - val_auc_01: 0.6747 - val_auc: 0.7962\n",
      "Epoch 195/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.0991 - auc_01: 0.9490 - auc: 0.9874 - val_loss: 0.5903 - val_auc_01: 0.6761 - val_auc: 0.7824\n",
      "Epoch 196/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1078 - auc_01: 0.9359 - auc: 0.9829 - val_loss: 0.5665 - val_auc_01: 0.6652 - val_auc: 0.8003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 36). These functions will not be directly callable after loading.\n",
      "2024-12-04 23:07:04.199101: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2024-12-04 23:07:04.199128: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2024-12-04 23:07:04.199700: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpw_8k3w4t\n",
      "2024-12-04 23:07:04.209391: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-12-04 23:07:04.209405: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpw_8k3w4t\n",
      "2024-12-04 23:07:04.239244: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2024-12-04 23:07:04.247939: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2024-12-04 23:07:04.504812: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpw_8k3w4t\n",
      "2024-12-04 23:07:04.563701: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 364003 microseconds.\n",
      "2024-12-04 23:07:04.699570: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(1500x1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 23:07:10.769466: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "86/86 [==============================] - 6s 29ms/step - loss: 0.4856 - auc_01: 0.5044 - auc: 0.4858 - val_loss: 0.4422 - val_auc_01: 0.5083 - val_auc: 0.4797\n",
      "Epoch 2/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4515 - auc_01: 0.5109 - auc: 0.5056 - val_loss: 0.4407 - val_auc_01: 0.5072 - val_auc: 0.5036\n",
      "Epoch 3/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4505 - auc_01: 0.5084 - auc: 0.5063 - val_loss: 0.4389 - val_auc_01: 0.5042 - val_auc: 0.4865\n",
      "Epoch 4/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4501 - auc_01: 0.5153 - auc: 0.5199 - val_loss: 0.4394 - val_auc_01: 0.4993 - val_auc: 0.4727\n",
      "Epoch 5/200\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.4499 - auc_01: 0.5146 - auc: 0.5085 - val_loss: 0.4412 - val_auc_01: 0.5048 - val_auc: 0.4889\n",
      "Epoch 6/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4471 - auc_01: 0.5176 - auc: 0.5378 - val_loss: 0.4416 - val_auc_01: 0.5074 - val_auc: 0.4832\n",
      "Epoch 7/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4481 - auc_01: 0.5135 - auc: 0.5262 - val_loss: 0.4399 - val_auc_01: 0.5041 - val_auc: 0.4799\n",
      "Epoch 8/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4466 - auc_01: 0.5285 - auc: 0.5360 - val_loss: 0.4393 - val_auc_01: 0.5084 - val_auc: 0.4946\n",
      "Epoch 9/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4430 - auc_01: 0.5291 - auc: 0.5481 - val_loss: 0.4403 - val_auc_01: 0.5082 - val_auc: 0.4960\n",
      "Epoch 10/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.4432 - auc_01: 0.5376 - auc: 0.5462 - val_loss: 0.4381 - val_auc_01: 0.5122 - val_auc: 0.5055\n",
      "Epoch 11/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4395 - auc_01: 0.5350 - auc: 0.5676 - val_loss: 0.4414 - val_auc_01: 0.5166 - val_auc: 0.4857\n",
      "Epoch 12/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4394 - auc_01: 0.5324 - auc: 0.5724 - val_loss: 0.4365 - val_auc_01: 0.5173 - val_auc: 0.5191\n",
      "Epoch 13/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4381 - auc_01: 0.5409 - auc: 0.5713 - val_loss: 0.4387 - val_auc_01: 0.5235 - val_auc: 0.5249\n",
      "Epoch 14/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4346 - auc_01: 0.5433 - auc: 0.6010 - val_loss: 0.4380 - val_auc_01: 0.5209 - val_auc: 0.5543\n",
      "Epoch 15/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4295 - auc_01: 0.5509 - auc: 0.6218 - val_loss: 0.4341 - val_auc_01: 0.5207 - val_auc: 0.5972\n",
      "Epoch 16/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4286 - auc_01: 0.5467 - auc: 0.6278 - val_loss: 0.4306 - val_auc_01: 0.5355 - val_auc: 0.6312\n",
      "Epoch 17/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.4211 - auc_01: 0.5554 - auc: 0.6601 - val_loss: 0.4270 - val_auc_01: 0.5397 - val_auc: 0.6340\n",
      "Epoch 18/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4152 - auc_01: 0.5649 - auc: 0.6733 - val_loss: 0.4227 - val_auc_01: 0.5644 - val_auc: 0.6300\n",
      "Epoch 19/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4103 - auc_01: 0.5671 - auc: 0.6887 - val_loss: 0.4185 - val_auc_01: 0.5633 - val_auc: 0.6800\n",
      "Epoch 20/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4020 - auc_01: 0.5798 - auc: 0.7129 - val_loss: 0.4130 - val_auc_01: 0.5759 - val_auc: 0.7005\n",
      "Epoch 21/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3939 - auc_01: 0.5915 - auc: 0.7339 - val_loss: 0.4128 - val_auc_01: 0.5669 - val_auc: 0.7071\n",
      "Epoch 22/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3905 - auc_01: 0.6003 - auc: 0.7416 - val_loss: 0.4354 - val_auc_01: 0.5894 - val_auc: 0.6947\n",
      "Epoch 23/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3858 - auc_01: 0.6096 - auc: 0.7504 - val_loss: 0.4070 - val_auc_01: 0.5817 - val_auc: 0.7177\n",
      "Epoch 24/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3769 - auc_01: 0.6150 - auc: 0.7640 - val_loss: 0.4077 - val_auc_01: 0.5730 - val_auc: 0.7255\n",
      "Epoch 25/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3691 - auc_01: 0.6272 - auc: 0.7780 - val_loss: 0.4037 - val_auc_01: 0.5881 - val_auc: 0.7261\n",
      "Epoch 26/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3669 - auc_01: 0.6328 - auc: 0.7863 - val_loss: 0.3995 - val_auc_01: 0.5903 - val_auc: 0.7356\n",
      "Epoch 27/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3587 - auc_01: 0.6443 - auc: 0.7906 - val_loss: 0.4038 - val_auc_01: 0.5877 - val_auc: 0.7382\n",
      "Epoch 28/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.3542 - auc_01: 0.6603 - auc: 0.7976 - val_loss: 0.4014 - val_auc_01: 0.6001 - val_auc: 0.7338\n",
      "Epoch 29/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3556 - auc_01: 0.6543 - auc: 0.7977 - val_loss: 0.3962 - val_auc_01: 0.6137 - val_auc: 0.7417\n",
      "Epoch 30/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3469 - auc_01: 0.6610 - auc: 0.8072 - val_loss: 0.3932 - val_auc_01: 0.6308 - val_auc: 0.7495\n",
      "Epoch 31/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3420 - auc_01: 0.6703 - auc: 0.8153 - val_loss: 0.4021 - val_auc_01: 0.6105 - val_auc: 0.7366\n",
      "Epoch 32/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3362 - auc_01: 0.6761 - auc: 0.8222 - val_loss: 0.4033 - val_auc_01: 0.6210 - val_auc: 0.7343\n",
      "Epoch 33/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.3346 - auc_01: 0.6872 - auc: 0.8217 - val_loss: 0.3996 - val_auc_01: 0.6145 - val_auc: 0.7499\n",
      "Epoch 34/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3309 - auc_01: 0.6841 - auc: 0.8316 - val_loss: 0.3902 - val_auc_01: 0.6262 - val_auc: 0.7571\n",
      "Epoch 35/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3230 - auc_01: 0.6923 - auc: 0.8355 - val_loss: 0.4054 - val_auc_01: 0.6314 - val_auc: 0.7374\n",
      "Epoch 36/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3257 - auc_01: 0.6983 - auc: 0.8329 - val_loss: 0.3896 - val_auc_01: 0.6390 - val_auc: 0.7590\n",
      "Epoch 37/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3115 - auc_01: 0.7069 - auc: 0.8469 - val_loss: 0.3944 - val_auc_01: 0.6387 - val_auc: 0.7587\n",
      "Epoch 38/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3054 - auc_01: 0.7112 - auc: 0.8584 - val_loss: 0.3989 - val_auc_01: 0.6277 - val_auc: 0.7649\n",
      "Epoch 39/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3053 - auc_01: 0.7075 - auc: 0.8565 - val_loss: 0.3977 - val_auc_01: 0.6306 - val_auc: 0.7643\n",
      "Epoch 40/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3033 - auc_01: 0.7183 - auc: 0.8619 - val_loss: 0.3945 - val_auc_01: 0.6245 - val_auc: 0.7726\n",
      "Epoch 41/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3099 - auc_01: 0.6991 - auc: 0.8526 - val_loss: 0.3913 - val_auc_01: 0.6359 - val_auc: 0.7712\n",
      "Epoch 42/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2991 - auc_01: 0.7169 - auc: 0.8652 - val_loss: 0.3948 - val_auc_01: 0.6301 - val_auc: 0.7719\n",
      "Epoch 43/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2969 - auc_01: 0.7157 - auc: 0.8653 - val_loss: 0.3996 - val_auc_01: 0.6344 - val_auc: 0.7716\n",
      "Epoch 44/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2861 - auc_01: 0.7350 - auc: 0.8761 - val_loss: 0.4015 - val_auc_01: 0.6337 - val_auc: 0.7665\n",
      "Epoch 45/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2862 - auc_01: 0.7316 - auc: 0.8766 - val_loss: 0.3983 - val_auc_01: 0.6331 - val_auc: 0.7784\n",
      "Epoch 46/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2851 - auc_01: 0.7367 - auc: 0.8779 - val_loss: 0.4002 - val_auc_01: 0.6355 - val_auc: 0.7769\n",
      "Epoch 47/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2838 - auc_01: 0.7386 - auc: 0.8831 - val_loss: 0.3948 - val_auc_01: 0.6429 - val_auc: 0.7788\n",
      "Epoch 48/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2742 - auc_01: 0.7431 - auc: 0.8871 - val_loss: 0.4132 - val_auc_01: 0.6389 - val_auc: 0.7669\n",
      "Epoch 49/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2713 - auc_01: 0.7530 - auc: 0.8858 - val_loss: 0.4232 - val_auc_01: 0.6297 - val_auc: 0.7723\n",
      "Epoch 50/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2755 - auc_01: 0.7404 - auc: 0.8868 - val_loss: 0.4058 - val_auc_01: 0.6540 - val_auc: 0.7685\n",
      "Epoch 51/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2688 - auc_01: 0.7538 - auc: 0.8899 - val_loss: 0.4128 - val_auc_01: 0.6382 - val_auc: 0.7705\n",
      "Epoch 52/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2677 - auc_01: 0.7631 - auc: 0.8892 - val_loss: 0.4011 - val_auc_01: 0.6430 - val_auc: 0.7794\n",
      "Epoch 53/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2551 - auc_01: 0.7707 - auc: 0.9034 - val_loss: 0.4042 - val_auc_01: 0.6476 - val_auc: 0.7766\n",
      "Epoch 54/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2606 - auc_01: 0.7611 - auc: 0.8966 - val_loss: 0.4057 - val_auc_01: 0.6428 - val_auc: 0.7821\n",
      "Epoch 55/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2569 - auc_01: 0.7666 - auc: 0.9037 - val_loss: 0.4030 - val_auc_01: 0.6469 - val_auc: 0.7816\n",
      "Epoch 56/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2548 - auc_01: 0.7743 - auc: 0.9028 - val_loss: 0.4065 - val_auc_01: 0.6500 - val_auc: 0.7780\n",
      "Epoch 57/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2506 - auc_01: 0.7666 - auc: 0.9056 - val_loss: 0.4051 - val_auc_01: 0.6487 - val_auc: 0.7912\n",
      "Epoch 58/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2449 - auc_01: 0.7780 - auc: 0.9097 - val_loss: 0.4130 - val_auc_01: 0.6484 - val_auc: 0.7795\n",
      "Epoch 59/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2475 - auc_01: 0.7879 - auc: 0.9081 - val_loss: 0.3990 - val_auc_01: 0.6454 - val_auc: 0.7962\n",
      "Epoch 60/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2462 - auc_01: 0.7739 - auc: 0.9149 - val_loss: 0.4065 - val_auc_01: 0.6480 - val_auc: 0.7929\n",
      "Epoch 61/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2403 - auc_01: 0.7901 - auc: 0.9152 - val_loss: 0.4041 - val_auc_01: 0.6568 - val_auc: 0.7928\n",
      "Epoch 62/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2344 - auc_01: 0.7918 - auc: 0.9188 - val_loss: 0.4082 - val_auc_01: 0.6545 - val_auc: 0.7870\n",
      "Epoch 63/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2317 - auc_01: 0.7981 - auc: 0.9213 - val_loss: 0.4139 - val_auc_01: 0.6556 - val_auc: 0.7851\n",
      "Epoch 64/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2295 - auc_01: 0.8031 - auc: 0.9205 - val_loss: 0.4104 - val_auc_01: 0.6536 - val_auc: 0.7910\n",
      "Epoch 65/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2289 - auc_01: 0.8055 - auc: 0.9214 - val_loss: 0.4141 - val_auc_01: 0.6639 - val_auc: 0.7800\n",
      "Epoch 66/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2308 - auc_01: 0.7980 - auc: 0.9219 - val_loss: 0.4238 - val_auc_01: 0.6555 - val_auc: 0.7828\n",
      "Epoch 67/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2236 - auc_01: 0.8103 - auc: 0.9261 - val_loss: 0.4188 - val_auc_01: 0.6630 - val_auc: 0.7821\n",
      "Epoch 68/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2242 - auc_01: 0.8083 - auc: 0.9213 - val_loss: 0.4122 - val_auc_01: 0.6655 - val_auc: 0.7940\n",
      "Epoch 69/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2271 - auc_01: 0.8003 - auc: 0.9236 - val_loss: 0.4096 - val_auc_01: 0.6619 - val_auc: 0.8013\n",
      "Epoch 70/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2223 - auc_01: 0.8085 - auc: 0.9262 - val_loss: 0.4141 - val_auc_01: 0.6601 - val_auc: 0.7929\n",
      "Epoch 71/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2224 - auc_01: 0.8093 - auc: 0.9268 - val_loss: 0.4283 - val_auc_01: 0.6546 - val_auc: 0.7872\n",
      "Epoch 72/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2118 - auc_01: 0.8263 - auc: 0.9330 - val_loss: 0.4349 - val_auc_01: 0.6613 - val_auc: 0.7908\n",
      "Epoch 73/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2205 - auc_01: 0.8181 - auc: 0.9283 - val_loss: 0.4261 - val_auc_01: 0.6648 - val_auc: 0.7916\n",
      "Epoch 74/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2135 - auc_01: 0.8251 - auc: 0.9308 - val_loss: 0.4164 - val_auc_01: 0.6611 - val_auc: 0.7923\n",
      "Epoch 75/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2216 - auc_01: 0.8121 - auc: 0.9266 - val_loss: 0.4124 - val_auc_01: 0.6725 - val_auc: 0.8002\n",
      "Epoch 76/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2132 - auc_01: 0.8184 - auc: 0.9304 - val_loss: 0.4174 - val_auc_01: 0.6682 - val_auc: 0.7952\n",
      "Epoch 77/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2026 - auc_01: 0.8281 - auc: 0.9386 - val_loss: 0.4342 - val_auc_01: 0.6706 - val_auc: 0.7922\n",
      "Epoch 78/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2054 - auc_01: 0.8274 - auc: 0.9349 - val_loss: 0.4220 - val_auc_01: 0.6707 - val_auc: 0.7900\n",
      "Epoch 79/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2013 - auc_01: 0.8406 - auc: 0.9411 - val_loss: 0.4289 - val_auc_01: 0.6602 - val_auc: 0.7972\n",
      "Epoch 80/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2014 - auc_01: 0.8248 - auc: 0.9414 - val_loss: 0.4321 - val_auc_01: 0.6616 - val_auc: 0.7957\n",
      "Epoch 81/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2022 - auc_01: 0.8341 - auc: 0.9394 - val_loss: 0.4315 - val_auc_01: 0.6648 - val_auc: 0.7966\n",
      "Epoch 82/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1944 - auc_01: 0.8441 - auc: 0.9449 - val_loss: 0.4319 - val_auc_01: 0.6648 - val_auc: 0.7970\n",
      "Epoch 83/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2075 - auc_01: 0.8255 - auc: 0.9383 - val_loss: 0.4274 - val_auc_01: 0.6744 - val_auc: 0.7964\n",
      "Epoch 84/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1972 - auc_01: 0.8342 - auc: 0.9448 - val_loss: 0.4515 - val_auc_01: 0.6663 - val_auc: 0.7873\n",
      "Epoch 85/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1932 - auc_01: 0.8410 - auc: 0.9406 - val_loss: 0.4401 - val_auc_01: 0.6650 - val_auc: 0.7941\n",
      "Epoch 86/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1935 - auc_01: 0.8408 - auc: 0.9422 - val_loss: 0.4482 - val_auc_01: 0.6604 - val_auc: 0.7845\n",
      "Epoch 87/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1858 - auc_01: 0.8547 - auc: 0.9477 - val_loss: 0.4447 - val_auc_01: 0.6758 - val_auc: 0.7927\n",
      "Epoch 88/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1929 - auc_01: 0.8432 - auc: 0.9466 - val_loss: 0.4445 - val_auc_01: 0.6692 - val_auc: 0.7955\n",
      "Epoch 89/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1905 - auc_01: 0.8488 - auc: 0.9474 - val_loss: 0.4338 - val_auc_01: 0.6729 - val_auc: 0.8031\n",
      "Epoch 90/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1858 - auc_01: 0.8556 - auc: 0.9502 - val_loss: 0.4486 - val_auc_01: 0.6756 - val_auc: 0.7910\n",
      "Epoch 91/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1961 - auc_01: 0.8416 - auc: 0.9435 - val_loss: 0.4286 - val_auc_01: 0.6692 - val_auc: 0.8038\n",
      "Epoch 92/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1986 - auc_01: 0.8387 - auc: 0.9436 - val_loss: 0.4295 - val_auc_01: 0.6701 - val_auc: 0.8012\n",
      "Epoch 93/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1868 - auc_01: 0.8455 - auc: 0.9500 - val_loss: 0.4615 - val_auc_01: 0.6751 - val_auc: 0.7888\n",
      "Epoch 94/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1837 - auc_01: 0.8615 - auc: 0.9506 - val_loss: 0.4561 - val_auc_01: 0.6748 - val_auc: 0.7920\n",
      "Epoch 95/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1782 - auc_01: 0.8624 - auc: 0.9503 - val_loss: 0.4458 - val_auc_01: 0.6746 - val_auc: 0.7996\n",
      "Epoch 96/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1813 - auc_01: 0.8538 - auc: 0.9509 - val_loss: 0.4535 - val_auc_01: 0.6771 - val_auc: 0.7928\n",
      "Epoch 97/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1738 - auc_01: 0.8663 - auc: 0.9559 - val_loss: 0.4440 - val_auc_01: 0.6814 - val_auc: 0.7986\n",
      "Epoch 98/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1784 - auc_01: 0.8619 - auc: 0.9514 - val_loss: 0.4492 - val_auc_01: 0.6860 - val_auc: 0.7939\n",
      "Epoch 99/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1801 - auc_01: 0.8533 - auc: 0.9512 - val_loss: 0.4458 - val_auc_01: 0.6769 - val_auc: 0.8032\n",
      "Epoch 100/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1666 - auc_01: 0.8671 - auc: 0.9609 - val_loss: 0.4712 - val_auc_01: 0.6718 - val_auc: 0.7923\n",
      "Epoch 101/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1749 - auc_01: 0.8632 - auc: 0.9563 - val_loss: 0.4382 - val_auc_01: 0.6790 - val_auc: 0.8083\n",
      "Epoch 102/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1750 - auc_01: 0.8640 - auc: 0.9542 - val_loss: 0.4590 - val_auc_01: 0.6771 - val_auc: 0.7987\n",
      "Epoch 103/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1691 - auc_01: 0.8692 - auc: 0.9581 - val_loss: 0.4521 - val_auc_01: 0.6666 - val_auc: 0.7997\n",
      "Epoch 104/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1730 - auc_01: 0.8757 - auc: 0.9560 - val_loss: 0.4678 - val_auc_01: 0.6704 - val_auc: 0.7941\n",
      "Epoch 105/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1702 - auc_01: 0.8736 - auc: 0.9568 - val_loss: 0.4700 - val_auc_01: 0.6705 - val_auc: 0.7934\n",
      "Epoch 106/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1716 - auc_01: 0.8639 - auc: 0.9576 - val_loss: 0.4733 - val_auc_01: 0.6738 - val_auc: 0.7956\n",
      "Epoch 107/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1635 - auc_01: 0.8768 - auc: 0.9617 - val_loss: 0.4740 - val_auc_01: 0.6520 - val_auc: 0.7949\n",
      "Epoch 108/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1623 - auc_01: 0.8669 - auc: 0.9607 - val_loss: 0.4852 - val_auc_01: 0.6768 - val_auc: 0.7954\n",
      "Epoch 109/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1658 - auc_01: 0.8745 - auc: 0.9597 - val_loss: 0.4735 - val_auc_01: 0.6832 - val_auc: 0.7897\n",
      "Epoch 110/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1710 - auc_01: 0.8719 - auc: 0.9597 - val_loss: 0.4817 - val_auc_01: 0.6789 - val_auc: 0.7941\n",
      "Epoch 111/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1596 - auc_01: 0.8786 - auc: 0.9616 - val_loss: 0.4847 - val_auc_01: 0.6725 - val_auc: 0.7918\n",
      "Epoch 112/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1562 - auc_01: 0.8932 - auc: 0.9676 - val_loss: 0.4703 - val_auc_01: 0.6825 - val_auc: 0.7948\n",
      "Epoch 113/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1610 - auc_01: 0.8759 - auc: 0.9597 - val_loss: 0.4730 - val_auc_01: 0.6833 - val_auc: 0.7997\n",
      "Epoch 114/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1594 - auc_01: 0.8794 - auc: 0.9628 - val_loss: 0.4723 - val_auc_01: 0.6720 - val_auc: 0.7944\n",
      "Epoch 115/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1611 - auc_01: 0.8797 - auc: 0.9619 - val_loss: 0.4651 - val_auc_01: 0.6770 - val_auc: 0.8069\n",
      "Epoch 116/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1554 - auc_01: 0.8830 - auc: 0.9639 - val_loss: 0.4748 - val_auc_01: 0.6745 - val_auc: 0.7925\n",
      "Epoch 117/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1599 - auc_01: 0.8772 - auc: 0.9631 - val_loss: 0.4744 - val_auc_01: 0.6668 - val_auc: 0.7999\n",
      "Epoch 118/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1537 - auc_01: 0.8940 - auc: 0.9660 - val_loss: 0.4768 - val_auc_01: 0.6782 - val_auc: 0.7936\n",
      "Epoch 119/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1590 - auc_01: 0.8837 - auc: 0.9635 - val_loss: 0.4799 - val_auc_01: 0.6768 - val_auc: 0.7969\n",
      "Epoch 120/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1597 - auc_01: 0.8817 - auc: 0.9647 - val_loss: 0.5096 - val_auc_01: 0.6810 - val_auc: 0.7843\n",
      "Epoch 121/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1575 - auc_01: 0.8832 - auc: 0.9645 - val_loss: 0.4841 - val_auc_01: 0.6775 - val_auc: 0.8007\n",
      "Epoch 122/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1546 - auc_01: 0.8877 - auc: 0.9651 - val_loss: 0.4818 - val_auc_01: 0.6865 - val_auc: 0.7908\n",
      "Epoch 123/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1534 - auc_01: 0.8847 - auc: 0.9651 - val_loss: 0.5019 - val_auc_01: 0.6765 - val_auc: 0.7871\n",
      "Epoch 124/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1506 - auc_01: 0.8852 - auc: 0.9668 - val_loss: 0.5039 - val_auc_01: 0.6696 - val_auc: 0.7910\n",
      "Epoch 125/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1471 - auc_01: 0.8978 - auc: 0.9702 - val_loss: 0.5128 - val_auc_01: 0.6775 - val_auc: 0.7935\n",
      "Epoch 126/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1499 - auc_01: 0.8938 - auc: 0.9683 - val_loss: 0.5207 - val_auc_01: 0.6772 - val_auc: 0.7940\n",
      "Epoch 127/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1532 - auc_01: 0.8936 - auc: 0.9676 - val_loss: 0.4977 - val_auc_01: 0.6786 - val_auc: 0.7949\n",
      "Epoch 128/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1460 - auc_01: 0.8891 - auc: 0.9696 - val_loss: 0.5161 - val_auc_01: 0.6694 - val_auc: 0.7912\n",
      "Epoch 129/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1481 - auc_01: 0.8881 - auc: 0.9685 - val_loss: 0.4856 - val_auc_01: 0.6862 - val_auc: 0.7987\n",
      "Epoch 130/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1531 - auc_01: 0.8842 - auc: 0.9670 - val_loss: 0.5068 - val_auc_01: 0.6769 - val_auc: 0.7946\n",
      "Epoch 131/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1479 - auc_01: 0.8899 - auc: 0.9664 - val_loss: 0.5161 - val_auc_01: 0.6761 - val_auc: 0.7909\n",
      "Epoch 132/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1450 - auc_01: 0.8941 - auc: 0.9717 - val_loss: 0.5127 - val_auc_01: 0.6775 - val_auc: 0.7945\n",
      "Epoch 133/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1365 - auc_01: 0.9085 - auc: 0.9737 - val_loss: 0.5250 - val_auc_01: 0.6717 - val_auc: 0.7856\n",
      "Epoch 134/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1449 - auc_01: 0.8972 - auc: 0.9698 - val_loss: 0.5062 - val_auc_01: 0.6835 - val_auc: 0.7928\n",
      "Epoch 135/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1524 - auc_01: 0.8948 - auc: 0.9685 - val_loss: 0.5162 - val_auc_01: 0.6862 - val_auc: 0.7950\n",
      "Epoch 136/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1475 - auc_01: 0.8992 - auc: 0.9693 - val_loss: 0.5156 - val_auc_01: 0.6857 - val_auc: 0.7959\n",
      "Epoch 137/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1434 - auc_01: 0.9030 - auc: 0.9724 - val_loss: 0.5107 - val_auc_01: 0.6828 - val_auc: 0.7995\n",
      "Epoch 138/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1435 - auc_01: 0.8997 - auc: 0.9701 - val_loss: 0.5228 - val_auc_01: 0.6852 - val_auc: 0.7936\n",
      "Epoch 139/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1362 - auc_01: 0.9097 - auc: 0.9726 - val_loss: 0.5252 - val_auc_01: 0.6789 - val_auc: 0.8014\n",
      "Epoch 140/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1340 - auc_01: 0.9067 - auc: 0.9741 - val_loss: 0.5301 - val_auc_01: 0.6816 - val_auc: 0.7926\n",
      "Epoch 141/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1399 - auc_01: 0.9026 - auc: 0.9722 - val_loss: 0.5309 - val_auc_01: 0.6833 - val_auc: 0.7981\n",
      "Epoch 142/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1398 - auc_01: 0.9015 - auc: 0.9717 - val_loss: 0.5012 - val_auc_01: 0.6763 - val_auc: 0.8034\n",
      "Epoch 143/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1357 - auc_01: 0.9071 - auc: 0.9727 - val_loss: 0.5203 - val_auc_01: 0.6790 - val_auc: 0.8009\n",
      "Epoch 144/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1354 - auc_01: 0.9061 - auc: 0.9727 - val_loss: 0.5151 - val_auc_01: 0.6816 - val_auc: 0.8021\n",
      "Epoch 145/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1325 - auc_01: 0.9162 - auc: 0.9737 - val_loss: 0.5050 - val_auc_01: 0.6779 - val_auc: 0.8013\n",
      "Epoch 146/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1259 - auc_01: 0.9185 - auc: 0.9791 - val_loss: 0.5305 - val_auc_01: 0.6795 - val_auc: 0.7948\n",
      "Epoch 147/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1299 - auc_01: 0.9096 - auc: 0.9740 - val_loss: 0.5169 - val_auc_01: 0.6805 - val_auc: 0.7983\n",
      "Epoch 148/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1372 - auc_01: 0.9056 - auc: 0.9738 - val_loss: 0.5301 - val_auc_01: 0.6768 - val_auc: 0.7936\n",
      "Epoch 149/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1242 - auc_01: 0.9142 - auc: 0.9773 - val_loss: 0.5252 - val_auc_01: 0.6758 - val_auc: 0.7986\n",
      "Epoch 150/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1249 - auc_01: 0.9183 - auc: 0.9776 - val_loss: 0.5335 - val_auc_01: 0.6843 - val_auc: 0.8016\n",
      "Epoch 151/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1330 - auc_01: 0.9091 - auc: 0.9766 - val_loss: 0.5122 - val_auc_01: 0.6819 - val_auc: 0.7979\n",
      "Epoch 152/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1409 - auc_01: 0.9109 - auc: 0.9720 - val_loss: 0.5399 - val_auc_01: 0.6789 - val_auc: 0.7952\n",
      "Epoch 153/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1244 - auc_01: 0.9132 - auc: 0.9764 - val_loss: 0.5443 - val_auc_01: 0.6836 - val_auc: 0.7899\n",
      "Epoch 154/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1224 - auc_01: 0.9235 - auc: 0.9778 - val_loss: 0.5349 - val_auc_01: 0.6758 - val_auc: 0.7999\n",
      "Epoch 155/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1252 - auc_01: 0.9136 - auc: 0.9764 - val_loss: 0.5356 - val_auc_01: 0.6768 - val_auc: 0.7912\n",
      "Epoch 156/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1229 - auc_01: 0.9187 - auc: 0.9770 - val_loss: 0.5267 - val_auc_01: 0.6908 - val_auc: 0.7985\n",
      "Epoch 157/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1319 - auc_01: 0.9116 - auc: 0.9747 - val_loss: 0.5284 - val_auc_01: 0.6780 - val_auc: 0.8024\n",
      "Epoch 158/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1233 - auc_01: 0.9194 - auc: 0.9801 - val_loss: 0.5576 - val_auc_01: 0.6832 - val_auc: 0.7910\n",
      "Epoch 159/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1249 - auc_01: 0.9237 - auc: 0.9791 - val_loss: 0.5431 - val_auc_01: 0.6879 - val_auc: 0.7913\n",
      "Epoch 160/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1306 - auc_01: 0.9119 - auc: 0.9743 - val_loss: 0.5248 - val_auc_01: 0.6788 - val_auc: 0.8008\n",
      "Epoch 161/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1214 - auc_01: 0.9214 - auc: 0.9790 - val_loss: 0.5216 - val_auc_01: 0.6858 - val_auc: 0.8009\n",
      "Epoch 162/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1274 - auc_01: 0.9131 - auc: 0.9777 - val_loss: 0.5166 - val_auc_01: 0.6875 - val_auc: 0.8077\n",
      "Epoch 163/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1274 - auc_01: 0.9133 - auc: 0.9770 - val_loss: 0.5064 - val_auc_01: 0.6857 - val_auc: 0.8135\n",
      "Epoch 164/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1172 - auc_01: 0.9220 - auc: 0.9806 - val_loss: 0.5418 - val_auc_01: 0.6864 - val_auc: 0.8031\n",
      "Epoch 165/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1195 - auc_01: 0.9263 - auc: 0.9804 - val_loss: 0.5432 - val_auc_01: 0.6800 - val_auc: 0.7972\n",
      "Epoch 166/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1266 - auc_01: 0.9188 - auc: 0.9756 - val_loss: 0.5403 - val_auc_01: 0.6891 - val_auc: 0.7957\n",
      "Epoch 167/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1212 - auc_01: 0.9250 - auc: 0.9792 - val_loss: 0.5425 - val_auc_01: 0.6943 - val_auc: 0.7941\n",
      "Epoch 168/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1154 - auc_01: 0.9272 - auc: 0.9801 - val_loss: 0.5374 - val_auc_01: 0.6832 - val_auc: 0.7986\n",
      "Epoch 169/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1119 - auc_01: 0.9384 - auc: 0.9817 - val_loss: 0.5483 - val_auc_01: 0.6794 - val_auc: 0.7973\n",
      "Epoch 170/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1290 - auc_01: 0.9135 - auc: 0.9756 - val_loss: 0.5218 - val_auc_01: 0.6771 - val_auc: 0.8034\n",
      "Epoch 171/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1181 - auc_01: 0.9258 - auc: 0.9816 - val_loss: 0.5150 - val_auc_01: 0.6881 - val_auc: 0.8038\n",
      "Epoch 172/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1248 - auc_01: 0.9159 - auc: 0.9774 - val_loss: 0.5582 - val_auc_01: 0.6930 - val_auc: 0.7938\n",
      "Epoch 173/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1159 - auc_01: 0.9272 - auc: 0.9804 - val_loss: 0.5562 - val_auc_01: 0.6890 - val_auc: 0.7856\n",
      "Epoch 174/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1137 - auc_01: 0.9318 - auc: 0.9829 - val_loss: 0.5411 - val_auc_01: 0.6895 - val_auc: 0.7945\n",
      "Epoch 175/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1210 - auc_01: 0.9223 - auc: 0.9792 - val_loss: 0.5395 - val_auc_01: 0.6843 - val_auc: 0.8030\n",
      "Epoch 176/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1210 - auc_01: 0.9273 - auc: 0.9788 - val_loss: 0.5321 - val_auc_01: 0.6906 - val_auc: 0.8028\n",
      "Epoch 177/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1198 - auc_01: 0.9240 - auc: 0.9799 - val_loss: 0.5478 - val_auc_01: 0.6862 - val_auc: 0.7986\n",
      "Epoch 178/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1200 - auc_01: 0.9231 - auc: 0.9793 - val_loss: 0.5385 - val_auc_01: 0.6856 - val_auc: 0.7985\n",
      "Epoch 179/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1141 - auc_01: 0.9303 - auc: 0.9809 - val_loss: 0.5600 - val_auc_01: 0.6922 - val_auc: 0.7947\n",
      "Epoch 180/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1135 - auc_01: 0.9289 - auc: 0.9807 - val_loss: 0.5722 - val_auc_01: 0.6866 - val_auc: 0.7935\n",
      "Epoch 181/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1225 - auc_01: 0.9220 - auc: 0.9793 - val_loss: 0.5445 - val_auc_01: 0.6880 - val_auc: 0.8023\n",
      "Epoch 182/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1169 - auc_01: 0.9293 - auc: 0.9794 - val_loss: 0.5784 - val_auc_01: 0.6902 - val_auc: 0.7921\n",
      "Epoch 183/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1194 - auc_01: 0.9263 - auc: 0.9809 - val_loss: 0.5662 - val_auc_01: 0.6862 - val_auc: 0.7970\n",
      "Epoch 184/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1114 - auc_01: 0.9329 - auc: 0.9823 - val_loss: 0.5493 - val_auc_01: 0.6832 - val_auc: 0.7960\n",
      "Epoch 185/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1123 - auc_01: 0.9322 - auc: 0.9817 - val_loss: 0.5512 - val_auc_01: 0.6909 - val_auc: 0.7950\n",
      "Epoch 186/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1076 - auc_01: 0.9349 - auc: 0.9843 - val_loss: 0.5507 - val_auc_01: 0.6879 - val_auc: 0.7946\n",
      "Epoch 187/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1069 - auc_01: 0.9330 - auc: 0.9836 - val_loss: 0.5422 - val_auc_01: 0.6851 - val_auc: 0.8027\n",
      "Epoch 188/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1121 - auc_01: 0.9359 - auc: 0.9814 - val_loss: 0.5344 - val_auc_01: 0.6835 - val_auc: 0.8041\n",
      "Epoch 189/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1137 - auc_01: 0.9316 - auc: 0.9810 - val_loss: 0.5554 - val_auc_01: 0.6912 - val_auc: 0.7928\n",
      "Epoch 190/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1015 - auc_01: 0.9441 - auc: 0.9852 - val_loss: 0.5835 - val_auc_01: 0.6858 - val_auc: 0.7816\n",
      "Epoch 191/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1150 - auc_01: 0.9311 - auc: 0.9818 - val_loss: 0.5559 - val_auc_01: 0.6778 - val_auc: 0.7975\n",
      "Epoch 192/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1120 - auc_01: 0.9299 - auc: 0.9826 - val_loss: 0.5906 - val_auc_01: 0.6939 - val_auc: 0.7851\n",
      "Epoch 193/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1131 - auc_01: 0.9384 - auc: 0.9818 - val_loss: 0.5768 - val_auc_01: 0.6806 - val_auc: 0.7920\n",
      "Epoch 194/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1097 - auc_01: 0.9379 - auc: 0.9830 - val_loss: 0.5729 - val_auc_01: 0.6792 - val_auc: 0.7931\n",
      "Epoch 195/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1090 - auc_01: 0.9381 - auc: 0.9839 - val_loss: 0.5632 - val_auc_01: 0.6921 - val_auc: 0.7834\n",
      "Epoch 196/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1089 - auc_01: 0.9317 - auc: 0.9835 - val_loss: 0.5597 - val_auc_01: 0.6916 - val_auc: 0.7920\n",
      "Epoch 197/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1019 - auc_01: 0.9412 - auc: 0.9840 - val_loss: 0.5817 - val_auc_01: 0.6896 - val_auc: 0.7888\n",
      "Epoch 198/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1053 - auc_01: 0.9390 - auc: 0.9851 - val_loss: 0.5752 - val_auc_01: 0.6910 - val_auc: 0.7916\n",
      "Epoch 199/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1094 - auc_01: 0.9315 - auc: 0.9825 - val_loss: 0.5910 - val_auc_01: 0.6949 - val_auc: 0.7934\n",
      "Epoch 200/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1071 - auc_01: 0.9383 - auc: 0.9841 - val_loss: 0.5920 - val_auc_01: 0.6899 - val_auc: 0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 36). These functions will not be directly callable after loading.\n",
      "2024-12-04 23:11:23.336845: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2024-12-04 23:11:23.336867: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2024-12-04 23:11:23.337454: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpenlxtd9d\n",
      "2024-12-04 23:11:23.346281: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-12-04 23:11:23.346294: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpenlxtd9d\n",
      "2024-12-04 23:11:23.373735: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2024-12-04 23:11:23.382157: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2024-12-04 23:11:23.623096: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpenlxtd9d\n",
      "2024-12-04 23:11:23.680264: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 342814 microseconds.\n",
      "2024-12-04 23:11:23.809696: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(1500x1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 23:11:29.242999: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "86/86 [==============================] - 6s 30ms/step - loss: 0.4942 - auc_01: 0.5070 - auc: 0.5040 - val_loss: 0.4444 - val_auc_01: 0.4979 - val_auc: 0.4936\n",
      "Epoch 2/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4519 - auc_01: 0.5167 - auc: 0.5100 - val_loss: 0.4442 - val_auc_01: 0.5070 - val_auc: 0.5114\n",
      "Epoch 3/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4518 - auc_01: 0.5064 - auc: 0.5042 - val_loss: 0.4441 - val_auc_01: 0.5030 - val_auc: 0.4971\n",
      "Epoch 4/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4513 - auc_01: 0.5155 - auc: 0.5126 - val_loss: 0.4441 - val_auc_01: 0.5032 - val_auc: 0.4824\n",
      "Epoch 5/200\n",
      "86/86 [==============================] - 2s 22ms/step - loss: 0.4512 - auc_01: 0.5174 - auc: 0.5077 - val_loss: 0.4445 - val_auc_01: 0.5084 - val_auc: 0.4902\n",
      "Epoch 6/200\n",
      "86/86 [==============================] - 2s 17ms/step - loss: 0.4496 - auc_01: 0.5116 - auc: 0.5239 - val_loss: 0.4439 - val_auc_01: 0.5104 - val_auc: 0.5001\n",
      "Epoch 7/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4493 - auc_01: 0.5113 - auc: 0.5202 - val_loss: 0.4435 - val_auc_01: 0.5097 - val_auc: 0.5054\n",
      "Epoch 8/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4482 - auc_01: 0.5170 - auc: 0.5450 - val_loss: 0.4441 - val_auc_01: 0.5069 - val_auc: 0.5040\n",
      "Epoch 9/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4482 - auc_01: 0.5161 - auc: 0.5345 - val_loss: 0.4435 - val_auc_01: 0.5119 - val_auc: 0.5032\n",
      "Epoch 10/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4502 - auc_01: 0.5208 - auc: 0.5262 - val_loss: 0.4449 - val_auc_01: 0.5093 - val_auc: 0.5021\n",
      "Epoch 11/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4447 - auc_01: 0.5241 - auc: 0.5613 - val_loss: 0.4424 - val_auc_01: 0.5168 - val_auc: 0.5134\n",
      "Epoch 12/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4444 - auc_01: 0.5232 - auc: 0.5522 - val_loss: 0.4455 - val_auc_01: 0.5129 - val_auc: 0.5198\n",
      "Epoch 13/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.4413 - auc_01: 0.5314 - auc: 0.5768 - val_loss: 0.4482 - val_auc_01: 0.5100 - val_auc: 0.5195\n",
      "Epoch 14/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4420 - auc_01: 0.5344 - auc: 0.5628 - val_loss: 0.4464 - val_auc_01: 0.5093 - val_auc: 0.5277\n",
      "Epoch 15/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4394 - auc_01: 0.5384 - auc: 0.5805 - val_loss: 0.4401 - val_auc_01: 0.5176 - val_auc: 0.5381\n",
      "Epoch 16/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4367 - auc_01: 0.5440 - auc: 0.5882 - val_loss: 0.4394 - val_auc_01: 0.5172 - val_auc: 0.5385\n",
      "Epoch 17/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4318 - auc_01: 0.5506 - auc: 0.6077 - val_loss: 0.4478 - val_auc_01: 0.5127 - val_auc: 0.5410\n",
      "Epoch 18/200\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.4326 - auc_01: 0.5525 - auc: 0.6084 - val_loss: 0.4379 - val_auc_01: 0.5201 - val_auc: 0.5776\n",
      "Epoch 19/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4302 - auc_01: 0.5552 - auc: 0.6258 - val_loss: 0.4356 - val_auc_01: 0.5210 - val_auc: 0.5976\n",
      "Epoch 20/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4223 - auc_01: 0.5733 - auc: 0.6599 - val_loss: 0.4302 - val_auc_01: 0.5278 - val_auc: 0.6352\n",
      "Epoch 21/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4167 - auc_01: 0.5831 - auc: 0.6719 - val_loss: 0.4209 - val_auc_01: 0.5611 - val_auc: 0.6427\n",
      "Epoch 22/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4067 - auc_01: 0.5966 - auc: 0.7024 - val_loss: 0.4182 - val_auc_01: 0.5815 - val_auc: 0.6390\n",
      "Epoch 23/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3985 - auc_01: 0.6117 - auc: 0.7264 - val_loss: 0.4252 - val_auc_01: 0.5765 - val_auc: 0.6552\n",
      "Epoch 24/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3929 - auc_01: 0.6181 - auc: 0.7348 - val_loss: 0.4077 - val_auc_01: 0.6103 - val_auc: 0.6693\n",
      "Epoch 25/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3815 - auc_01: 0.6399 - auc: 0.7512 - val_loss: 0.4049 - val_auc_01: 0.6088 - val_auc: 0.7026\n",
      "Epoch 26/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.3697 - auc_01: 0.6537 - auc: 0.7781 - val_loss: 0.3997 - val_auc_01: 0.6040 - val_auc: 0.7184\n",
      "Epoch 27/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3730 - auc_01: 0.6562 - auc: 0.7698 - val_loss: 0.3929 - val_auc_01: 0.6068 - val_auc: 0.7377\n",
      "Epoch 28/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3597 - auc_01: 0.6600 - auc: 0.7961 - val_loss: 0.4019 - val_auc_01: 0.6142 - val_auc: 0.7306\n",
      "Epoch 29/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3605 - auc_01: 0.6611 - auc: 0.7935 - val_loss: 0.3896 - val_auc_01: 0.6122 - val_auc: 0.7389\n",
      "Epoch 30/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3503 - auc_01: 0.6706 - auc: 0.8041 - val_loss: 0.3929 - val_auc_01: 0.6145 - val_auc: 0.7371\n",
      "Epoch 31/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3465 - auc_01: 0.6678 - auc: 0.8116 - val_loss: 0.3898 - val_auc_01: 0.6105 - val_auc: 0.7376\n",
      "Epoch 32/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3395 - auc_01: 0.6852 - auc: 0.8171 - val_loss: 0.3883 - val_auc_01: 0.6096 - val_auc: 0.7540\n",
      "Epoch 33/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3353 - auc_01: 0.6870 - auc: 0.8234 - val_loss: 0.3895 - val_auc_01: 0.6140 - val_auc: 0.7454\n",
      "Epoch 34/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3283 - auc_01: 0.6896 - auc: 0.8314 - val_loss: 0.3899 - val_auc_01: 0.6081 - val_auc: 0.7451\n",
      "Epoch 35/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3209 - auc_01: 0.7043 - auc: 0.8398 - val_loss: 0.3935 - val_auc_01: 0.6093 - val_auc: 0.7490\n",
      "Epoch 36/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3226 - auc_01: 0.7026 - auc: 0.8443 - val_loss: 0.3968 - val_auc_01: 0.6121 - val_auc: 0.7480\n",
      "Epoch 37/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3222 - auc_01: 0.7082 - auc: 0.8407 - val_loss: 0.4009 - val_auc_01: 0.6154 - val_auc: 0.7360\n",
      "Epoch 38/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3139 - auc_01: 0.7089 - auc: 0.8489 - val_loss: 0.3946 - val_auc_01: 0.6130 - val_auc: 0.7541\n",
      "Epoch 39/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3107 - auc_01: 0.7161 - auc: 0.8504 - val_loss: 0.3968 - val_auc_01: 0.6170 - val_auc: 0.7559\n",
      "Epoch 40/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2955 - auc_01: 0.7286 - auc: 0.8665 - val_loss: 0.3988 - val_auc_01: 0.6241 - val_auc: 0.7512\n",
      "Epoch 41/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2949 - auc_01: 0.7316 - auc: 0.8677 - val_loss: 0.3937 - val_auc_01: 0.6169 - val_auc: 0.7627\n",
      "Epoch 42/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2910 - auc_01: 0.7372 - auc: 0.8698 - val_loss: 0.3977 - val_auc_01: 0.6237 - val_auc: 0.7540\n",
      "Epoch 43/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2825 - auc_01: 0.7423 - auc: 0.8789 - val_loss: 0.4089 - val_auc_01: 0.6211 - val_auc: 0.7476\n",
      "Epoch 44/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2925 - auc_01: 0.7294 - auc: 0.8735 - val_loss: 0.3922 - val_auc_01: 0.6221 - val_auc: 0.7662\n",
      "Epoch 45/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2830 - auc_01: 0.7461 - auc: 0.8792 - val_loss: 0.3908 - val_auc_01: 0.6306 - val_auc: 0.7671\n",
      "Epoch 46/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2824 - auc_01: 0.7483 - auc: 0.8774 - val_loss: 0.4029 - val_auc_01: 0.6205 - val_auc: 0.7594\n",
      "Epoch 47/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2816 - auc_01: 0.7421 - auc: 0.8795 - val_loss: 0.3952 - val_auc_01: 0.6277 - val_auc: 0.7690\n",
      "Epoch 48/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2681 - auc_01: 0.7583 - auc: 0.8911 - val_loss: 0.3927 - val_auc_01: 0.6303 - val_auc: 0.7728\n",
      "Epoch 49/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2664 - auc_01: 0.7616 - auc: 0.8904 - val_loss: 0.4070 - val_auc_01: 0.6289 - val_auc: 0.7636\n",
      "Epoch 50/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2704 - auc_01: 0.7571 - auc: 0.8930 - val_loss: 0.3974 - val_auc_01: 0.6300 - val_auc: 0.7731\n",
      "Epoch 51/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2628 - auc_01: 0.7555 - auc: 0.8945 - val_loss: 0.3949 - val_auc_01: 0.6349 - val_auc: 0.7703\n",
      "Epoch 52/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2618 - auc_01: 0.7608 - auc: 0.9027 - val_loss: 0.4217 - val_auc_01: 0.6447 - val_auc: 0.7536\n",
      "Epoch 53/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2597 - auc_01: 0.7636 - auc: 0.8983 - val_loss: 0.3952 - val_auc_01: 0.6325 - val_auc: 0.7762\n",
      "Epoch 54/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2507 - auc_01: 0.7767 - auc: 0.9100 - val_loss: 0.4005 - val_auc_01: 0.6459 - val_auc: 0.7743\n",
      "Epoch 55/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2558 - auc_01: 0.7658 - auc: 0.9061 - val_loss: 0.3943 - val_auc_01: 0.6297 - val_auc: 0.7842\n",
      "Epoch 56/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2484 - auc_01: 0.7807 - auc: 0.9086 - val_loss: 0.4019 - val_auc_01: 0.6351 - val_auc: 0.7745\n",
      "Epoch 57/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2420 - auc_01: 0.7901 - auc: 0.9122 - val_loss: 0.4015 - val_auc_01: 0.6405 - val_auc: 0.7798\n",
      "Epoch 58/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2497 - auc_01: 0.7811 - auc: 0.9089 - val_loss: 0.4169 - val_auc_01: 0.6439 - val_auc: 0.7734\n",
      "Epoch 59/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2342 - auc_01: 0.7920 - auc: 0.9166 - val_loss: 0.4234 - val_auc_01: 0.6396 - val_auc: 0.7679\n",
      "Epoch 60/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2373 - auc_01: 0.7878 - auc: 0.9154 - val_loss: 0.4199 - val_auc_01: 0.6425 - val_auc: 0.7663\n",
      "Epoch 61/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2353 - auc_01: 0.7932 - auc: 0.9199 - val_loss: 0.4099 - val_auc_01: 0.6458 - val_auc: 0.7778\n",
      "Epoch 62/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2336 - auc_01: 0.7949 - auc: 0.9218 - val_loss: 0.4328 - val_auc_01: 0.6385 - val_auc: 0.7654\n",
      "Epoch 63/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2314 - auc_01: 0.8096 - auc: 0.9220 - val_loss: 0.4237 - val_auc_01: 0.6505 - val_auc: 0.7695\n",
      "Epoch 64/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2334 - auc_01: 0.8074 - auc: 0.9232 - val_loss: 0.4136 - val_auc_01: 0.6543 - val_auc: 0.7742\n",
      "Epoch 65/200\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.2176 - auc_01: 0.8171 - auc: 0.9306 - val_loss: 0.4217 - val_auc_01: 0.6564 - val_auc: 0.7757\n",
      "Epoch 66/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2269 - auc_01: 0.8104 - auc: 0.9250 - val_loss: 0.4250 - val_auc_01: 0.6469 - val_auc: 0.7758\n",
      "Epoch 67/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2216 - auc_01: 0.8109 - auc: 0.9282 - val_loss: 0.4227 - val_auc_01: 0.6467 - val_auc: 0.7768\n",
      "Epoch 68/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2203 - auc_01: 0.8186 - auc: 0.9308 - val_loss: 0.4271 - val_auc_01: 0.6442 - val_auc: 0.7728\n",
      "Epoch 69/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2184 - auc_01: 0.8107 - auc: 0.9296 - val_loss: 0.4366 - val_auc_01: 0.6446 - val_auc: 0.7688\n",
      "Epoch 70/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2175 - auc_01: 0.8205 - auc: 0.9273 - val_loss: 0.4307 - val_auc_01: 0.6468 - val_auc: 0.7705\n",
      "Epoch 71/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2190 - auc_01: 0.8168 - auc: 0.9292 - val_loss: 0.4345 - val_auc_01: 0.6499 - val_auc: 0.7730\n",
      "Epoch 72/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2117 - auc_01: 0.8260 - auc: 0.9308 - val_loss: 0.4301 - val_auc_01: 0.6428 - val_auc: 0.7734\n",
      "Epoch 73/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2112 - auc_01: 0.8217 - auc: 0.9331 - val_loss: 0.4386 - val_auc_01: 0.6508 - val_auc: 0.7684\n",
      "Epoch 74/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2054 - auc_01: 0.8332 - auc: 0.9390 - val_loss: 0.4509 - val_auc_01: 0.6532 - val_auc: 0.7605\n",
      "Epoch 75/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2053 - auc_01: 0.8328 - auc: 0.9363 - val_loss: 0.4458 - val_auc_01: 0.6491 - val_auc: 0.7696\n",
      "Epoch 76/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2015 - auc_01: 0.8342 - auc: 0.9364 - val_loss: 0.4303 - val_auc_01: 0.6452 - val_auc: 0.7799\n",
      "Epoch 77/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2058 - auc_01: 0.8236 - auc: 0.9357 - val_loss: 0.4331 - val_auc_01: 0.6487 - val_auc: 0.7776\n",
      "Epoch 78/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2061 - auc_01: 0.8356 - auc: 0.9394 - val_loss: 0.4249 - val_auc_01: 0.6536 - val_auc: 0.7832\n",
      "Epoch 79/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1953 - auc_01: 0.8437 - auc: 0.9448 - val_loss: 0.4723 - val_auc_01: 0.6437 - val_auc: 0.7604\n",
      "Epoch 80/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1955 - auc_01: 0.8429 - auc: 0.9418 - val_loss: 0.4282 - val_auc_01: 0.6383 - val_auc: 0.7841\n",
      "Epoch 81/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2010 - auc_01: 0.8345 - auc: 0.9388 - val_loss: 0.4407 - val_auc_01: 0.6511 - val_auc: 0.7783\n",
      "Epoch 82/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1971 - auc_01: 0.8395 - auc: 0.9442 - val_loss: 0.4547 - val_auc_01: 0.6525 - val_auc: 0.7746\n",
      "Epoch 83/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1998 - auc_01: 0.8334 - auc: 0.9413 - val_loss: 0.4380 - val_auc_01: 0.6474 - val_auc: 0.7807\n",
      "Epoch 84/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1915 - auc_01: 0.8471 - auc: 0.9472 - val_loss: 0.4460 - val_auc_01: 0.6451 - val_auc: 0.7783\n",
      "Epoch 85/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1925 - auc_01: 0.8435 - auc: 0.9468 - val_loss: 0.4478 - val_auc_01: 0.6503 - val_auc: 0.7755\n",
      "Epoch 86/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1899 - auc_01: 0.8581 - auc: 0.9487 - val_loss: 0.4737 - val_auc_01: 0.6521 - val_auc: 0.7683\n",
      "Epoch 87/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1845 - auc_01: 0.8505 - auc: 0.9482 - val_loss: 0.4484 - val_auc_01: 0.6475 - val_auc: 0.7785\n",
      "Epoch 88/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1847 - auc_01: 0.8528 - auc: 0.9516 - val_loss: 0.4723 - val_auc_01: 0.6517 - val_auc: 0.7718\n",
      "Epoch 89/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1931 - auc_01: 0.8570 - auc: 0.9463 - val_loss: 0.4467 - val_auc_01: 0.6523 - val_auc: 0.7781\n",
      "Epoch 90/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1820 - auc_01: 0.8583 - auc: 0.9491 - val_loss: 0.4619 - val_auc_01: 0.6455 - val_auc: 0.7712\n",
      "Epoch 91/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1875 - auc_01: 0.8527 - auc: 0.9490 - val_loss: 0.4576 - val_auc_01: 0.6534 - val_auc: 0.7723\n",
      "Epoch 92/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1742 - auc_01: 0.8712 - auc: 0.9566 - val_loss: 0.4607 - val_auc_01: 0.6535 - val_auc: 0.7748\n",
      "Epoch 93/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1808 - auc_01: 0.8523 - auc: 0.9516 - val_loss: 0.4604 - val_auc_01: 0.6627 - val_auc: 0.7787\n",
      "Epoch 94/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1850 - auc_01: 0.8499 - auc: 0.9510 - val_loss: 0.4713 - val_auc_01: 0.6602 - val_auc: 0.7749\n",
      "Epoch 95/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1835 - auc_01: 0.8506 - auc: 0.9515 - val_loss: 0.4540 - val_auc_01: 0.6535 - val_auc: 0.7767\n",
      "Epoch 96/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1761 - auc_01: 0.8662 - auc: 0.9547 - val_loss: 0.4768 - val_auc_01: 0.6601 - val_auc: 0.7710\n",
      "Epoch 97/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1805 - auc_01: 0.8618 - auc: 0.9529 - val_loss: 0.4561 - val_auc_01: 0.6488 - val_auc: 0.7814\n",
      "Epoch 98/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1734 - auc_01: 0.8667 - auc: 0.9559 - val_loss: 0.4577 - val_auc_01: 0.6582 - val_auc: 0.7850\n",
      "Epoch 99/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1676 - auc_01: 0.8724 - auc: 0.9597 - val_loss: 0.4741 - val_auc_01: 0.6614 - val_auc: 0.7717\n",
      "Epoch 100/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1767 - auc_01: 0.8574 - auc: 0.9570 - val_loss: 0.4627 - val_auc_01: 0.6631 - val_auc: 0.7809\n",
      "Epoch 101/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1676 - auc_01: 0.8759 - auc: 0.9590 - val_loss: 0.4698 - val_auc_01: 0.6449 - val_auc: 0.7847\n",
      "Epoch 102/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1761 - auc_01: 0.8669 - auc: 0.9568 - val_loss: 0.4602 - val_auc_01: 0.6525 - val_auc: 0.7860\n",
      "Epoch 103/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1765 - auc_01: 0.8717 - auc: 0.9552 - val_loss: 0.4684 - val_auc_01: 0.6520 - val_auc: 0.7787\n",
      "Epoch 104/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1698 - auc_01: 0.8747 - auc: 0.9584 - val_loss: 0.4922 - val_auc_01: 0.6526 - val_auc: 0.7752\n",
      "Epoch 105/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1631 - auc_01: 0.8814 - auc: 0.9623 - val_loss: 0.4815 - val_auc_01: 0.6569 - val_auc: 0.7788\n",
      "Epoch 106/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1587 - auc_01: 0.8853 - auc: 0.9638 - val_loss: 0.4800 - val_auc_01: 0.6505 - val_auc: 0.7829\n",
      "Epoch 107/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1599 - auc_01: 0.8865 - auc: 0.9622 - val_loss: 0.4845 - val_auc_01: 0.6586 - val_auc: 0.7751\n",
      "Epoch 108/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1638 - auc_01: 0.8786 - auc: 0.9598 - val_loss: 0.4614 - val_auc_01: 0.6534 - val_auc: 0.7857\n",
      "Epoch 109/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1600 - auc_01: 0.8874 - auc: 0.9644 - val_loss: 0.5123 - val_auc_01: 0.6595 - val_auc: 0.7688\n",
      "Epoch 110/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1529 - auc_01: 0.8925 - auc: 0.9643 - val_loss: 0.4810 - val_auc_01: 0.6641 - val_auc: 0.7806\n",
      "Epoch 111/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1528 - auc_01: 0.8936 - auc: 0.9662 - val_loss: 0.5002 - val_auc_01: 0.6605 - val_auc: 0.7725\n",
      "Epoch 112/200\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.1599 - auc_01: 0.8756 - auc: 0.9627 - val_loss: 0.4947 - val_auc_01: 0.6653 - val_auc: 0.7741\n",
      "Epoch 113/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1537 - auc_01: 0.8922 - auc: 0.9659 - val_loss: 0.4863 - val_auc_01: 0.6529 - val_auc: 0.7783\n",
      "Epoch 114/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1618 - auc_01: 0.8773 - auc: 0.9607 - val_loss: 0.4864 - val_auc_01: 0.6634 - val_auc: 0.7794\n",
      "Epoch 115/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1547 - auc_01: 0.8927 - auc: 0.9648 - val_loss: 0.4927 - val_auc_01: 0.6553 - val_auc: 0.7815\n",
      "Epoch 116/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1558 - auc_01: 0.8854 - auc: 0.9635 - val_loss: 0.5016 - val_auc_01: 0.6637 - val_auc: 0.7732\n",
      "Epoch 117/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1563 - auc_01: 0.8847 - auc: 0.9635 - val_loss: 0.4870 - val_auc_01: 0.6582 - val_auc: 0.7833\n",
      "Epoch 118/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1577 - auc_01: 0.8821 - auc: 0.9638 - val_loss: 0.4817 - val_auc_01: 0.6606 - val_auc: 0.7832\n",
      "Epoch 119/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1469 - auc_01: 0.8975 - auc: 0.9691 - val_loss: 0.4890 - val_auc_01: 0.6651 - val_auc: 0.7782\n",
      "Epoch 120/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1482 - auc_01: 0.8988 - auc: 0.9670 - val_loss: 0.5177 - val_auc_01: 0.6637 - val_auc: 0.7721\n",
      "Epoch 121/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1557 - auc_01: 0.8930 - auc: 0.9647 - val_loss: 0.5021 - val_auc_01: 0.6679 - val_auc: 0.7705\n",
      "Epoch 122/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1482 - auc_01: 0.8945 - auc: 0.9661 - val_loss: 0.5069 - val_auc_01: 0.6621 - val_auc: 0.7739\n",
      "Epoch 123/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1509 - auc_01: 0.8934 - auc: 0.9669 - val_loss: 0.5134 - val_auc_01: 0.6629 - val_auc: 0.7704\n",
      "Epoch 124/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1535 - auc_01: 0.8862 - auc: 0.9656 - val_loss: 0.4947 - val_auc_01: 0.6675 - val_auc: 0.7747\n",
      "Epoch 125/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1462 - auc_01: 0.9022 - auc: 0.9677 - val_loss: 0.5026 - val_auc_01: 0.6665 - val_auc: 0.7729\n",
      "Epoch 126/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1507 - auc_01: 0.8814 - auc: 0.9675 - val_loss: 0.5227 - val_auc_01: 0.6728 - val_auc: 0.7681\n",
      "Epoch 127/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1477 - auc_01: 0.8901 - auc: 0.9677 - val_loss: 0.5099 - val_auc_01: 0.6626 - val_auc: 0.7788\n",
      "Epoch 128/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1482 - auc_01: 0.8967 - auc: 0.9687 - val_loss: 0.5001 - val_auc_01: 0.6611 - val_auc: 0.7802\n",
      "Epoch 129/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1479 - auc_01: 0.8923 - auc: 0.9695 - val_loss: 0.5127 - val_auc_01: 0.6576 - val_auc: 0.7693\n",
      "Epoch 130/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1435 - auc_01: 0.9047 - auc: 0.9687 - val_loss: 0.5238 - val_auc_01: 0.6683 - val_auc: 0.7701\n",
      "Epoch 131/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1393 - auc_01: 0.9098 - auc: 0.9697 - val_loss: 0.5164 - val_auc_01: 0.6673 - val_auc: 0.7716\n",
      "Epoch 132/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1488 - auc_01: 0.8963 - auc: 0.9680 - val_loss: 0.5336 - val_auc_01: 0.6667 - val_auc: 0.7632\n",
      "Epoch 133/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1391 - auc_01: 0.9033 - auc: 0.9714 - val_loss: 0.5361 - val_auc_01: 0.6574 - val_auc: 0.7613\n",
      "Epoch 134/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1382 - auc_01: 0.9030 - auc: 0.9717 - val_loss: 0.5033 - val_auc_01: 0.6625 - val_auc: 0.7761\n",
      "Epoch 135/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1360 - auc_01: 0.9090 - auc: 0.9725 - val_loss: 0.5165 - val_auc_01: 0.6649 - val_auc: 0.7702\n",
      "Epoch 136/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1339 - auc_01: 0.9099 - auc: 0.9740 - val_loss: 0.5322 - val_auc_01: 0.6572 - val_auc: 0.7698\n",
      "Epoch 137/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1352 - auc_01: 0.9117 - auc: 0.9722 - val_loss: 0.5231 - val_auc_01: 0.6656 - val_auc: 0.7723\n",
      "Epoch 138/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1337 - auc_01: 0.9088 - auc: 0.9745 - val_loss: 0.5258 - val_auc_01: 0.6625 - val_auc: 0.7713\n",
      "Epoch 139/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1344 - auc_01: 0.9077 - auc: 0.9749 - val_loss: 0.5171 - val_auc_01: 0.6669 - val_auc: 0.7728\n",
      "Epoch 140/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1369 - auc_01: 0.9198 - auc: 0.9733 - val_loss: 0.5262 - val_auc_01: 0.6660 - val_auc: 0.7740\n",
      "Epoch 141/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1311 - auc_01: 0.9110 - auc: 0.9772 - val_loss: 0.5103 - val_auc_01: 0.6755 - val_auc: 0.7778\n",
      "Epoch 142/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1379 - auc_01: 0.9056 - auc: 0.9723 - val_loss: 0.5025 - val_auc_01: 0.6714 - val_auc: 0.7829\n",
      "Epoch 143/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1364 - auc_01: 0.9071 - auc: 0.9714 - val_loss: 0.5281 - val_auc_01: 0.6784 - val_auc: 0.7734\n",
      "Epoch 144/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1322 - auc_01: 0.9157 - auc: 0.9749 - val_loss: 0.5184 - val_auc_01: 0.6721 - val_auc: 0.7804\n",
      "Epoch 145/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1233 - auc_01: 0.9224 - auc: 0.9770 - val_loss: 0.5304 - val_auc_01: 0.6692 - val_auc: 0.7714\n",
      "Epoch 146/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1345 - auc_01: 0.9061 - auc: 0.9741 - val_loss: 0.5135 - val_auc_01: 0.6616 - val_auc: 0.7805\n",
      "Epoch 147/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1309 - auc_01: 0.9119 - auc: 0.9755 - val_loss: 0.5320 - val_auc_01: 0.6665 - val_auc: 0.7741\n",
      "Epoch 148/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1320 - auc_01: 0.9177 - auc: 0.9771 - val_loss: 0.5235 - val_auc_01: 0.6652 - val_auc: 0.7826\n",
      "Epoch 149/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1355 - auc_01: 0.9024 - auc: 0.9733 - val_loss: 0.5308 - val_auc_01: 0.6671 - val_auc: 0.7754\n",
      "Epoch 150/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1255 - auc_01: 0.9213 - auc: 0.9757 - val_loss: 0.5312 - val_auc_01: 0.6642 - val_auc: 0.7707\n",
      "Epoch 151/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1272 - auc_01: 0.9212 - auc: 0.9747 - val_loss: 0.5439 - val_auc_01: 0.6670 - val_auc: 0.7717\n",
      "Epoch 152/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1299 - auc_01: 0.9126 - auc: 0.9743 - val_loss: 0.5490 - val_auc_01: 0.6731 - val_auc: 0.7677\n",
      "Epoch 153/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1248 - auc_01: 0.9217 - auc: 0.9770 - val_loss: 0.5612 - val_auc_01: 0.6698 - val_auc: 0.7670\n",
      "Epoch 154/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1324 - auc_01: 0.9143 - auc: 0.9736 - val_loss: 0.5349 - val_auc_01: 0.6561 - val_auc: 0.7706\n",
      "Epoch 155/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1240 - auc_01: 0.9177 - auc: 0.9783 - val_loss: 0.5331 - val_auc_01: 0.6625 - val_auc: 0.7708\n",
      "Epoch 156/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1245 - auc_01: 0.9210 - auc: 0.9772 - val_loss: 0.5450 - val_auc_01: 0.6628 - val_auc: 0.7626\n",
      "Epoch 157/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1322 - auc_01: 0.9110 - auc: 0.9746 - val_loss: 0.5399 - val_auc_01: 0.6700 - val_auc: 0.7720\n",
      "Epoch 158/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1353 - auc_01: 0.9085 - auc: 0.9751 - val_loss: 0.5554 - val_auc_01: 0.6678 - val_auc: 0.7668\n",
      "Epoch 159/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1230 - auc_01: 0.9183 - auc: 0.9779 - val_loss: 0.5487 - val_auc_01: 0.6716 - val_auc: 0.7706\n",
      "Epoch 160/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1220 - auc_01: 0.9195 - auc: 0.9793 - val_loss: 0.5450 - val_auc_01: 0.6776 - val_auc: 0.7660\n",
      "Epoch 161/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1223 - auc_01: 0.9206 - auc: 0.9764 - val_loss: 0.5267 - val_auc_01: 0.6685 - val_auc: 0.7768\n",
      "Epoch 162/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1178 - auc_01: 0.9223 - auc: 0.9801 - val_loss: 0.5468 - val_auc_01: 0.6689 - val_auc: 0.7721\n",
      "Epoch 163/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1197 - auc_01: 0.9302 - auc: 0.9801 - val_loss: 0.5494 - val_auc_01: 0.6706 - val_auc: 0.7701\n",
      "Epoch 164/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1242 - auc_01: 0.9197 - auc: 0.9797 - val_loss: 0.5682 - val_auc_01: 0.6686 - val_auc: 0.7597\n",
      "Epoch 165/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1204 - auc_01: 0.9250 - auc: 0.9785 - val_loss: 0.5669 - val_auc_01: 0.6719 - val_auc: 0.7656\n",
      "Epoch 166/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1273 - auc_01: 0.9156 - auc: 0.9772 - val_loss: 0.5620 - val_auc_01: 0.6674 - val_auc: 0.7686\n",
      "Epoch 167/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1156 - auc_01: 0.9271 - auc: 0.9812 - val_loss: 0.5536 - val_auc_01: 0.6638 - val_auc: 0.7688\n",
      "Epoch 168/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1248 - auc_01: 0.9206 - auc: 0.9778 - val_loss: 0.5559 - val_auc_01: 0.6640 - val_auc: 0.7704\n",
      "Epoch 169/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1225 - auc_01: 0.9218 - auc: 0.9790 - val_loss: 0.5255 - val_auc_01: 0.6669 - val_auc: 0.7801\n",
      "Epoch 170/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1170 - auc_01: 0.9309 - auc: 0.9802 - val_loss: 0.5512 - val_auc_01: 0.6671 - val_auc: 0.7706\n",
      "Epoch 171/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1242 - auc_01: 0.9157 - auc: 0.9781 - val_loss: 0.5467 - val_auc_01: 0.6693 - val_auc: 0.7729\n",
      "Epoch 172/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1177 - auc_01: 0.9171 - auc: 0.9803 - val_loss: 0.5572 - val_auc_01: 0.6615 - val_auc: 0.7718\n",
      "Epoch 173/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1139 - auc_01: 0.9314 - auc: 0.9795 - val_loss: 0.5464 - val_auc_01: 0.6609 - val_auc: 0.7789\n",
      "Epoch 174/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1131 - auc_01: 0.9292 - auc: 0.9828 - val_loss: 0.5745 - val_auc_01: 0.6690 - val_auc: 0.7605\n",
      "Epoch 175/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1201 - auc_01: 0.9231 - auc: 0.9783 - val_loss: 0.5522 - val_auc_01: 0.6686 - val_auc: 0.7722\n",
      "Epoch 176/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1134 - auc_01: 0.9276 - auc: 0.9817 - val_loss: 0.5456 - val_auc_01: 0.6715 - val_auc: 0.7757\n",
      "Epoch 177/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1142 - auc_01: 0.9333 - auc: 0.9811 - val_loss: 0.5782 - val_auc_01: 0.6676 - val_auc: 0.7646\n",
      "Epoch 178/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1101 - auc_01: 0.9300 - auc: 0.9814 - val_loss: 0.5785 - val_auc_01: 0.6732 - val_auc: 0.7634\n",
      "Epoch 179/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1159 - auc_01: 0.9261 - auc: 0.9804 - val_loss: 0.5626 - val_auc_01: 0.6657 - val_auc: 0.7652\n",
      "Epoch 180/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1141 - auc_01: 0.9311 - auc: 0.9805 - val_loss: 0.5578 - val_auc_01: 0.6650 - val_auc: 0.7738\n",
      "Epoch 181/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1184 - auc_01: 0.9280 - auc: 0.9805 - val_loss: 0.5308 - val_auc_01: 0.6770 - val_auc: 0.7808\n",
      "Epoch 182/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1088 - auc_01: 0.9363 - auc: 0.9831 - val_loss: 0.5659 - val_auc_01: 0.6712 - val_auc: 0.7660\n",
      "Epoch 183/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1174 - auc_01: 0.9306 - auc: 0.9783 - val_loss: 0.5595 - val_auc_01: 0.6756 - val_auc: 0.7681\n",
      "Epoch 184/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1126 - auc_01: 0.9343 - auc: 0.9824 - val_loss: 0.5786 - val_auc_01: 0.6745 - val_auc: 0.7684\n",
      "Epoch 185/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1175 - auc_01: 0.9215 - auc: 0.9809 - val_loss: 0.5704 - val_auc_01: 0.6709 - val_auc: 0.7697\n",
      "Epoch 186/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1062 - auc_01: 0.9395 - auc: 0.9832 - val_loss: 0.5918 - val_auc_01: 0.6742 - val_auc: 0.7627\n",
      "Epoch 187/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1211 - auc_01: 0.9268 - auc: 0.9804 - val_loss: 0.5806 - val_auc_01: 0.6703 - val_auc: 0.7622\n",
      "Epoch 188/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1136 - auc_01: 0.9375 - auc: 0.9795 - val_loss: 0.5730 - val_auc_01: 0.6644 - val_auc: 0.7686\n",
      "Epoch 189/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1095 - auc_01: 0.9360 - auc: 0.9831 - val_loss: 0.5912 - val_auc_01: 0.6748 - val_auc: 0.7582\n",
      "Epoch 190/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1171 - auc_01: 0.9252 - auc: 0.9803 - val_loss: 0.5733 - val_auc_01: 0.6688 - val_auc: 0.7666\n",
      "Epoch 191/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1092 - auc_01: 0.9369 - auc: 0.9823 - val_loss: 0.5477 - val_auc_01: 0.6731 - val_auc: 0.7753\n",
      "Epoch 192/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1138 - auc_01: 0.9291 - auc: 0.9805 - val_loss: 0.5750 - val_auc_01: 0.6753 - val_auc: 0.7687\n",
      "Epoch 193/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1033 - auc_01: 0.9441 - auc: 0.9849 - val_loss: 0.5837 - val_auc_01: 0.6751 - val_auc: 0.7616\n",
      "Epoch 194/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1061 - auc_01: 0.9433 - auc: 0.9839 - val_loss: 0.5965 - val_auc_01: 0.6779 - val_auc: 0.7593\n",
      "Epoch 195/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1048 - auc_01: 0.9450 - auc: 0.9844 - val_loss: 0.5697 - val_auc_01: 0.6706 - val_auc: 0.7722\n",
      "Epoch 196/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.0993 - auc_01: 0.9432 - auc: 0.9859 - val_loss: 0.5983 - val_auc_01: 0.6671 - val_auc: 0.7673\n",
      "Epoch 197/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1043 - auc_01: 0.9382 - auc: 0.9831 - val_loss: 0.5757 - val_auc_01: 0.6683 - val_auc: 0.7718\n",
      "Epoch 198/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1030 - auc_01: 0.9422 - auc: 0.9837 - val_loss: 0.5856 - val_auc_01: 0.6769 - val_auc: 0.7688\n",
      "Epoch 199/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1037 - auc_01: 0.9388 - auc: 0.9852 - val_loss: 0.5761 - val_auc_01: 0.6743 - val_auc: 0.7680\n",
      "Epoch 200/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.0963 - auc_01: 0.9483 - auc: 0.9872 - val_loss: 0.6007 - val_auc_01: 0.6801 - val_auc: 0.7680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 36). These functions will not be directly callable after loading.\n",
      "2024-12-04 23:15:37.614409: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2024-12-04 23:15:37.614438: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2024-12-04 23:15:37.615129: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmppvowrkka\n",
      "2024-12-04 23:15:37.624631: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-12-04 23:15:37.624643: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmppvowrkka\n",
      "2024-12-04 23:15:37.655304: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2024-12-04 23:15:37.663729: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2024-12-04 23:15:37.908563: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmppvowrkka\n",
      "2024-12-04 23:15:37.965124: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 349997 microseconds.\n",
      "2024-12-04 23:15:38.096111: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(1500x1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 23:15:43.496045: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "86/86 [==============================] - 6s 28ms/step - loss: 0.4772 - auc_01: 0.5099 - auc: 0.4864 - val_loss: 0.4780 - val_auc_01: 0.5109 - val_auc: 0.4819\n",
      "Epoch 2/200\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.4439 - auc_01: 0.5032 - auc: 0.5094 - val_loss: 0.4783 - val_auc_01: 0.5092 - val_auc: 0.4524\n",
      "Epoch 3/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4428 - auc_01: 0.5125 - auc: 0.5106 - val_loss: 0.4758 - val_auc_01: 0.5089 - val_auc: 0.4537\n",
      "Epoch 4/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4429 - auc_01: 0.5164 - auc: 0.5077 - val_loss: 0.4717 - val_auc_01: 0.5105 - val_auc: 0.4471\n",
      "Epoch 5/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4430 - auc_01: 0.5122 - auc: 0.5069 - val_loss: 0.4806 - val_auc_01: 0.5123 - val_auc: 0.4676\n",
      "Epoch 6/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4413 - auc_01: 0.5123 - auc: 0.5256 - val_loss: 0.4773 - val_auc_01: 0.5157 - val_auc: 0.4745\n",
      "Epoch 7/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4418 - auc_01: 0.5088 - auc: 0.5296 - val_loss: 0.4726 - val_auc_01: 0.5093 - val_auc: 0.4807\n",
      "Epoch 8/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4404 - auc_01: 0.5223 - auc: 0.5325 - val_loss: 0.4764 - val_auc_01: 0.5109 - val_auc: 0.4753\n",
      "Epoch 9/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4389 - auc_01: 0.5218 - auc: 0.5387 - val_loss: 0.4748 - val_auc_01: 0.5184 - val_auc: 0.4679\n",
      "Epoch 10/200\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.4390 - auc_01: 0.5159 - auc: 0.5413 - val_loss: 0.4826 - val_auc_01: 0.5137 - val_auc: 0.4785\n",
      "Epoch 11/200\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.4355 - auc_01: 0.5342 - auc: 0.5667 - val_loss: 0.4768 - val_auc_01: 0.5149 - val_auc: 0.4767\n",
      "Epoch 12/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4363 - auc_01: 0.5225 - auc: 0.5612 - val_loss: 0.4771 - val_auc_01: 0.5167 - val_auc: 0.4859\n",
      "Epoch 13/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4343 - auc_01: 0.5288 - auc: 0.5638 - val_loss: 0.4742 - val_auc_01: 0.5211 - val_auc: 0.4852\n",
      "Epoch 14/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4323 - auc_01: 0.5388 - auc: 0.5706 - val_loss: 0.4815 - val_auc_01: 0.5204 - val_auc: 0.5193\n",
      "Epoch 15/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4293 - auc_01: 0.5411 - auc: 0.5939 - val_loss: 0.4801 - val_auc_01: 0.5204 - val_auc: 0.5361\n",
      "Epoch 16/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4293 - auc_01: 0.5437 - auc: 0.5982 - val_loss: 0.4697 - val_auc_01: 0.5192 - val_auc: 0.5241\n",
      "Epoch 17/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4233 - auc_01: 0.5540 - auc: 0.6140 - val_loss: 0.4752 - val_auc_01: 0.5286 - val_auc: 0.5756\n",
      "Epoch 18/200\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.4166 - auc_01: 0.5684 - auc: 0.6428 - val_loss: 0.4626 - val_auc_01: 0.5354 - val_auc: 0.6551\n",
      "Epoch 19/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4106 - auc_01: 0.5702 - auc: 0.6696 - val_loss: 0.4504 - val_auc_01: 0.5438 - val_auc: 0.6630\n",
      "Epoch 20/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.4016 - auc_01: 0.5837 - auc: 0.6888 - val_loss: 0.4508 - val_auc_01: 0.5575 - val_auc: 0.7087\n",
      "Epoch 21/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3966 - auc_01: 0.5781 - auc: 0.7149 - val_loss: 0.4365 - val_auc_01: 0.5527 - val_auc: 0.7259\n",
      "Epoch 22/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3918 - auc_01: 0.5886 - auc: 0.7291 - val_loss: 0.4380 - val_auc_01: 0.6040 - val_auc: 0.7370\n",
      "Epoch 23/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3789 - auc_01: 0.6210 - auc: 0.7600 - val_loss: 0.4322 - val_auc_01: 0.6081 - val_auc: 0.7399\n",
      "Epoch 24/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3681 - auc_01: 0.6282 - auc: 0.7775 - val_loss: 0.4283 - val_auc_01: 0.6096 - val_auc: 0.7534\n",
      "Epoch 25/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3675 - auc_01: 0.6296 - auc: 0.7764 - val_loss: 0.4355 - val_auc_01: 0.6219 - val_auc: 0.7466\n",
      "Epoch 26/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3615 - auc_01: 0.6435 - auc: 0.7855 - val_loss: 0.4198 - val_auc_01: 0.6193 - val_auc: 0.7608\n",
      "Epoch 27/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3574 - auc_01: 0.6572 - auc: 0.7922 - val_loss: 0.4137 - val_auc_01: 0.6275 - val_auc: 0.7648\n",
      "Epoch 28/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3538 - auc_01: 0.6433 - auc: 0.7973 - val_loss: 0.4164 - val_auc_01: 0.6374 - val_auc: 0.7635\n",
      "Epoch 29/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3513 - auc_01: 0.6557 - auc: 0.7990 - val_loss: 0.4091 - val_auc_01: 0.6397 - val_auc: 0.7709\n",
      "Epoch 30/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3383 - auc_01: 0.6684 - auc: 0.8173 - val_loss: 0.4116 - val_auc_01: 0.6393 - val_auc: 0.7720\n",
      "Epoch 31/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3365 - auc_01: 0.6723 - auc: 0.8177 - val_loss: 0.4078 - val_auc_01: 0.6451 - val_auc: 0.7771\n",
      "Epoch 32/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3316 - auc_01: 0.6772 - auc: 0.8234 - val_loss: 0.4163 - val_auc_01: 0.6467 - val_auc: 0.7737\n",
      "Epoch 33/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3297 - auc_01: 0.6811 - auc: 0.8237 - val_loss: 0.4112 - val_auc_01: 0.6499 - val_auc: 0.7790\n",
      "Epoch 34/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3245 - auc_01: 0.6869 - auc: 0.8331 - val_loss: 0.4019 - val_auc_01: 0.6415 - val_auc: 0.7837\n",
      "Epoch 35/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3251 - auc_01: 0.6776 - auc: 0.8328 - val_loss: 0.4125 - val_auc_01: 0.6473 - val_auc: 0.7824\n",
      "Epoch 36/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3192 - auc_01: 0.6921 - auc: 0.8424 - val_loss: 0.4032 - val_auc_01: 0.6531 - val_auc: 0.7864\n",
      "Epoch 37/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3132 - auc_01: 0.6947 - auc: 0.8453 - val_loss: 0.4212 - val_auc_01: 0.6511 - val_auc: 0.7790\n",
      "Epoch 38/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3193 - auc_01: 0.6872 - auc: 0.8382 - val_loss: 0.4113 - val_auc_01: 0.6550 - val_auc: 0.7843\n",
      "Epoch 39/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3109 - auc_01: 0.7024 - auc: 0.8500 - val_loss: 0.4304 - val_auc_01: 0.6525 - val_auc: 0.7680\n",
      "Epoch 40/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3075 - auc_01: 0.7096 - auc: 0.8511 - val_loss: 0.4004 - val_auc_01: 0.6631 - val_auc: 0.7881\n",
      "Epoch 41/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3018 - auc_01: 0.7063 - auc: 0.8609 - val_loss: 0.4168 - val_auc_01: 0.6582 - val_auc: 0.7843\n",
      "Epoch 42/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2939 - auc_01: 0.7259 - auc: 0.8613 - val_loss: 0.4356 - val_auc_01: 0.6495 - val_auc: 0.7737\n",
      "Epoch 43/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2958 - auc_01: 0.7177 - auc: 0.8606 - val_loss: 0.4232 - val_auc_01: 0.6454 - val_auc: 0.7870\n",
      "Epoch 44/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2926 - auc_01: 0.7207 - auc: 0.8688 - val_loss: 0.4176 - val_auc_01: 0.6563 - val_auc: 0.7890\n",
      "Epoch 45/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2893 - auc_01: 0.7347 - auc: 0.8697 - val_loss: 0.4147 - val_auc_01: 0.6544 - val_auc: 0.7913\n",
      "Epoch 46/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2831 - auc_01: 0.7441 - auc: 0.8746 - val_loss: 0.4245 - val_auc_01: 0.6586 - val_auc: 0.7838\n",
      "Epoch 47/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2801 - auc_01: 0.7286 - auc: 0.8812 - val_loss: 0.4610 - val_auc_01: 0.6515 - val_auc: 0.7718\n",
      "Epoch 48/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2708 - auc_01: 0.7564 - auc: 0.8824 - val_loss: 0.4276 - val_auc_01: 0.6586 - val_auc: 0.7879\n",
      "Epoch 49/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2751 - auc_01: 0.7357 - auc: 0.8835 - val_loss: 0.4020 - val_auc_01: 0.6577 - val_auc: 0.8002\n",
      "Epoch 50/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2675 - auc_01: 0.7526 - auc: 0.8876 - val_loss: 0.4060 - val_auc_01: 0.6575 - val_auc: 0.8048\n",
      "Epoch 51/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2703 - auc_01: 0.7574 - auc: 0.8876 - val_loss: 0.4201 - val_auc_01: 0.6603 - val_auc: 0.7922\n",
      "Epoch 52/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2704 - auc_01: 0.7449 - auc: 0.8883 - val_loss: 0.4422 - val_auc_01: 0.6654 - val_auc: 0.7848\n",
      "Epoch 53/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2621 - auc_01: 0.7651 - auc: 0.8953 - val_loss: 0.4403 - val_auc_01: 0.6566 - val_auc: 0.7899\n",
      "Epoch 54/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2591 - auc_01: 0.7563 - auc: 0.8969 - val_loss: 0.4221 - val_auc_01: 0.6587 - val_auc: 0.8003\n",
      "Epoch 55/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2530 - auc_01: 0.7661 - auc: 0.9002 - val_loss: 0.4507 - val_auc_01: 0.6629 - val_auc: 0.7855\n",
      "Epoch 56/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2516 - auc_01: 0.7658 - auc: 0.9032 - val_loss: 0.4275 - val_auc_01: 0.6662 - val_auc: 0.7939\n",
      "Epoch 57/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2440 - auc_01: 0.7689 - auc: 0.9081 - val_loss: 0.4242 - val_auc_01: 0.6657 - val_auc: 0.7991\n",
      "Epoch 58/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2499 - auc_01: 0.7694 - auc: 0.9024 - val_loss: 0.4475 - val_auc_01: 0.6673 - val_auc: 0.7871\n",
      "Epoch 59/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2446 - auc_01: 0.7852 - auc: 0.9101 - val_loss: 0.4478 - val_auc_01: 0.6637 - val_auc: 0.7851\n",
      "Epoch 60/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2441 - auc_01: 0.7819 - auc: 0.9070 - val_loss: 0.4373 - val_auc_01: 0.6745 - val_auc: 0.7908\n",
      "Epoch 61/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2399 - auc_01: 0.7808 - auc: 0.9136 - val_loss: 0.4488 - val_auc_01: 0.6587 - val_auc: 0.7849\n",
      "Epoch 62/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2473 - auc_01: 0.7684 - auc: 0.9103 - val_loss: 0.4276 - val_auc_01: 0.6644 - val_auc: 0.7985\n",
      "Epoch 63/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2329 - auc_01: 0.7945 - auc: 0.9141 - val_loss: 0.4305 - val_auc_01: 0.6753 - val_auc: 0.7993\n",
      "Epoch 64/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2317 - auc_01: 0.7885 - auc: 0.9209 - val_loss: 0.4531 - val_auc_01: 0.6802 - val_auc: 0.7887\n",
      "Epoch 65/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2406 - auc_01: 0.7840 - auc: 0.9125 - val_loss: 0.4236 - val_auc_01: 0.6756 - val_auc: 0.8027\n",
      "Epoch 66/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2414 - auc_01: 0.7788 - auc: 0.9102 - val_loss: 0.4260 - val_auc_01: 0.6729 - val_auc: 0.8011\n",
      "Epoch 67/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2297 - auc_01: 0.7888 - auc: 0.9183 - val_loss: 0.4200 - val_auc_01: 0.6758 - val_auc: 0.8069\n",
      "Epoch 68/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2230 - auc_01: 0.8148 - auc: 0.9246 - val_loss: 0.4500 - val_auc_01: 0.6696 - val_auc: 0.7960\n",
      "Epoch 69/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2274 - auc_01: 0.7870 - auc: 0.9232 - val_loss: 0.4490 - val_auc_01: 0.6728 - val_auc: 0.7938\n",
      "Epoch 70/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2230 - auc_01: 0.8082 - auc: 0.9245 - val_loss: 0.4315 - val_auc_01: 0.6708 - val_auc: 0.8029\n",
      "Epoch 71/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2188 - auc_01: 0.8115 - auc: 0.9249 - val_loss: 0.4363 - val_auc_01: 0.6779 - val_auc: 0.8008\n",
      "Epoch 72/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2183 - auc_01: 0.8104 - auc: 0.9258 - val_loss: 0.4758 - val_auc_01: 0.6763 - val_auc: 0.7875\n",
      "Epoch 73/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2173 - auc_01: 0.8087 - auc: 0.9274 - val_loss: 0.4510 - val_auc_01: 0.6835 - val_auc: 0.7963\n",
      "Epoch 74/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2207 - auc_01: 0.8028 - auc: 0.9256 - val_loss: 0.4583 - val_auc_01: 0.6815 - val_auc: 0.7995\n",
      "Epoch 75/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.2170 - auc_01: 0.8076 - auc: 0.9256 - val_loss: 0.4548 - val_auc_01: 0.6817 - val_auc: 0.8012\n",
      "Epoch 76/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2095 - auc_01: 0.8210 - auc: 0.9316 - val_loss: 0.4741 - val_auc_01: 0.6835 - val_auc: 0.7930\n",
      "Epoch 77/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.2091 - auc_01: 0.8173 - auc: 0.9320 - val_loss: 0.4486 - val_auc_01: 0.6830 - val_auc: 0.7977\n",
      "Epoch 78/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2111 - auc_01: 0.8104 - auc: 0.9325 - val_loss: 0.4904 - val_auc_01: 0.6865 - val_auc: 0.7874\n",
      "Epoch 79/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2046 - auc_01: 0.8307 - auc: 0.9345 - val_loss: 0.4380 - val_auc_01: 0.6837 - val_auc: 0.8088\n",
      "Epoch 80/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2081 - auc_01: 0.8194 - auc: 0.9345 - val_loss: 0.4673 - val_auc_01: 0.6806 - val_auc: 0.7960\n",
      "Epoch 81/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2073 - auc_01: 0.8245 - auc: 0.9378 - val_loss: 0.4553 - val_auc_01: 0.6804 - val_auc: 0.7986\n",
      "Epoch 82/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2048 - auc_01: 0.8190 - auc: 0.9363 - val_loss: 0.4348 - val_auc_01: 0.6918 - val_auc: 0.8118\n",
      "Epoch 83/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1970 - auc_01: 0.8321 - auc: 0.9407 - val_loss: 0.4851 - val_auc_01: 0.6890 - val_auc: 0.7951\n",
      "Epoch 84/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1956 - auc_01: 0.8309 - auc: 0.9446 - val_loss: 0.4342 - val_auc_01: 0.6910 - val_auc: 0.8107\n",
      "Epoch 85/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1925 - auc_01: 0.8453 - auc: 0.9416 - val_loss: 0.5048 - val_auc_01: 0.6784 - val_auc: 0.7738\n",
      "Epoch 86/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2007 - auc_01: 0.8283 - auc: 0.9381 - val_loss: 0.4692 - val_auc_01: 0.6813 - val_auc: 0.7913\n",
      "Epoch 87/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1958 - auc_01: 0.8429 - auc: 0.9428 - val_loss: 0.4533 - val_auc_01: 0.6771 - val_auc: 0.8000\n",
      "Epoch 88/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1934 - auc_01: 0.8336 - auc: 0.9437 - val_loss: 0.4835 - val_auc_01: 0.6782 - val_auc: 0.7931\n",
      "Epoch 89/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1903 - auc_01: 0.8456 - auc: 0.9458 - val_loss: 0.4430 - val_auc_01: 0.6875 - val_auc: 0.8110\n",
      "Epoch 90/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1879 - auc_01: 0.8353 - auc: 0.9451 - val_loss: 0.4529 - val_auc_01: 0.6933 - val_auc: 0.8060\n",
      "Epoch 91/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1839 - auc_01: 0.8501 - auc: 0.9523 - val_loss: 0.4505 - val_auc_01: 0.6984 - val_auc: 0.8100\n",
      "Epoch 92/200\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1892 - auc_01: 0.8408 - auc: 0.9460 - val_loss: 0.4738 - val_auc_01: 0.6991 - val_auc: 0.8004\n",
      "Epoch 93/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1889 - auc_01: 0.8445 - auc: 0.9473 - val_loss: 0.4561 - val_auc_01: 0.6941 - val_auc: 0.8088\n",
      "Epoch 94/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1865 - auc_01: 0.8495 - auc: 0.9482 - val_loss: 0.4714 - val_auc_01: 0.6978 - val_auc: 0.8102\n",
      "Epoch 95/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1835 - auc_01: 0.8493 - auc: 0.9502 - val_loss: 0.4410 - val_auc_01: 0.7024 - val_auc: 0.8166\n",
      "Epoch 96/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1852 - auc_01: 0.8545 - auc: 0.9483 - val_loss: 0.4654 - val_auc_01: 0.6965 - val_auc: 0.8082\n",
      "Epoch 97/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1757 - auc_01: 0.8645 - auc: 0.9522 - val_loss: 0.4775 - val_auc_01: 0.6937 - val_auc: 0.8042\n",
      "Epoch 98/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1719 - auc_01: 0.8679 - auc: 0.9573 - val_loss: 0.4755 - val_auc_01: 0.6999 - val_auc: 0.8014\n",
      "Epoch 99/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1777 - auc_01: 0.8588 - auc: 0.9549 - val_loss: 0.4644 - val_auc_01: 0.6935 - val_auc: 0.8110\n",
      "Epoch 100/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1733 - auc_01: 0.8591 - auc: 0.9550 - val_loss: 0.4569 - val_auc_01: 0.6967 - val_auc: 0.8131\n",
      "Epoch 101/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1782 - auc_01: 0.8624 - auc: 0.9509 - val_loss: 0.4708 - val_auc_01: 0.6850 - val_auc: 0.8114\n",
      "Epoch 102/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1715 - auc_01: 0.8690 - auc: 0.9554 - val_loss: 0.4697 - val_auc_01: 0.6890 - val_auc: 0.8087\n",
      "Epoch 103/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1713 - auc_01: 0.8628 - auc: 0.9539 - val_loss: 0.4834 - val_auc_01: 0.6862 - val_auc: 0.8082\n",
      "Epoch 104/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1761 - auc_01: 0.8504 - auc: 0.9538 - val_loss: 0.4666 - val_auc_01: 0.6939 - val_auc: 0.8099\n",
      "Epoch 105/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1723 - auc_01: 0.8582 - auc: 0.9545 - val_loss: 0.5091 - val_auc_01: 0.6912 - val_auc: 0.7987\n",
      "Epoch 106/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1706 - auc_01: 0.8723 - auc: 0.9540 - val_loss: 0.4855 - val_auc_01: 0.6902 - val_auc: 0.8054\n",
      "Epoch 107/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1721 - auc_01: 0.8668 - auc: 0.9562 - val_loss: 0.4793 - val_auc_01: 0.6964 - val_auc: 0.8065\n",
      "Epoch 108/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1644 - auc_01: 0.8695 - auc: 0.9586 - val_loss: 0.5221 - val_auc_01: 0.6918 - val_auc: 0.7923\n",
      "Epoch 109/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1651 - auc_01: 0.8660 - auc: 0.9601 - val_loss: 0.4985 - val_auc_01: 0.6919 - val_auc: 0.7993\n",
      "Epoch 110/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1669 - auc_01: 0.8705 - auc: 0.9601 - val_loss: 0.4935 - val_auc_01: 0.6881 - val_auc: 0.8023\n",
      "Epoch 111/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1650 - auc_01: 0.8727 - auc: 0.9575 - val_loss: 0.5110 - val_auc_01: 0.6929 - val_auc: 0.7999\n",
      "Epoch 112/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1664 - auc_01: 0.8704 - auc: 0.9586 - val_loss: 0.4791 - val_auc_01: 0.7000 - val_auc: 0.8074\n",
      "Epoch 113/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1612 - auc_01: 0.8778 - auc: 0.9623 - val_loss: 0.5189 - val_auc_01: 0.6908 - val_auc: 0.7969\n",
      "Epoch 114/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1627 - auc_01: 0.8776 - auc: 0.9603 - val_loss: 0.4853 - val_auc_01: 0.6997 - val_auc: 0.8075\n",
      "Epoch 115/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1602 - auc_01: 0.8790 - auc: 0.9588 - val_loss: 0.4925 - val_auc_01: 0.7027 - val_auc: 0.8024\n",
      "Epoch 116/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1563 - auc_01: 0.8819 - auc: 0.9640 - val_loss: 0.5236 - val_auc_01: 0.6885 - val_auc: 0.7956\n",
      "Epoch 117/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1494 - auc_01: 0.8947 - auc: 0.9653 - val_loss: 0.5074 - val_auc_01: 0.6956 - val_auc: 0.8062\n",
      "Epoch 118/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1596 - auc_01: 0.8843 - auc: 0.9609 - val_loss: 0.4684 - val_auc_01: 0.7059 - val_auc: 0.8163\n",
      "Epoch 119/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1574 - auc_01: 0.8785 - auc: 0.9632 - val_loss: 0.5060 - val_auc_01: 0.6956 - val_auc: 0.8021\n",
      "Epoch 120/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1514 - auc_01: 0.8839 - auc: 0.9673 - val_loss: 0.5160 - val_auc_01: 0.6946 - val_auc: 0.8065\n",
      "Epoch 121/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1536 - auc_01: 0.8802 - auc: 0.9645 - val_loss: 0.5064 - val_auc_01: 0.6983 - val_auc: 0.8033\n",
      "Epoch 122/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1569 - auc_01: 0.8882 - auc: 0.9629 - val_loss: 0.5072 - val_auc_01: 0.6953 - val_auc: 0.8024\n",
      "Epoch 123/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1549 - auc_01: 0.8931 - auc: 0.9631 - val_loss: 0.5379 - val_auc_01: 0.6949 - val_auc: 0.7923\n",
      "Epoch 124/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1561 - auc_01: 0.8763 - auc: 0.9630 - val_loss: 0.4774 - val_auc_01: 0.6987 - val_auc: 0.8096\n",
      "Epoch 125/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1498 - auc_01: 0.8945 - auc: 0.9657 - val_loss: 0.5013 - val_auc_01: 0.7052 - val_auc: 0.8081\n",
      "Epoch 126/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1497 - auc_01: 0.8950 - auc: 0.9681 - val_loss: 0.4873 - val_auc_01: 0.7028 - val_auc: 0.8180\n",
      "Epoch 127/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1483 - auc_01: 0.8915 - auc: 0.9675 - val_loss: 0.4935 - val_auc_01: 0.6990 - val_auc: 0.8150\n",
      "Epoch 128/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1521 - auc_01: 0.8858 - auc: 0.9658 - val_loss: 0.5132 - val_auc_01: 0.7003 - val_auc: 0.8018\n",
      "Epoch 129/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1459 - auc_01: 0.8986 - auc: 0.9688 - val_loss: 0.5118 - val_auc_01: 0.6938 - val_auc: 0.8080\n",
      "Epoch 130/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1466 - auc_01: 0.8969 - auc: 0.9699 - val_loss: 0.5108 - val_auc_01: 0.7042 - val_auc: 0.8099\n",
      "Epoch 131/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1485 - auc_01: 0.8935 - auc: 0.9676 - val_loss: 0.5110 - val_auc_01: 0.7031 - val_auc: 0.8091\n",
      "Epoch 132/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1459 - auc_01: 0.8972 - auc: 0.9672 - val_loss: 0.5032 - val_auc_01: 0.7127 - val_auc: 0.8115\n",
      "Epoch 133/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1542 - auc_01: 0.8817 - auc: 0.9653 - val_loss: 0.5103 - val_auc_01: 0.7040 - val_auc: 0.8073\n",
      "Epoch 134/200\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1396 - auc_01: 0.9014 - auc: 0.9715 - val_loss: 0.5133 - val_auc_01: 0.7027 - val_auc: 0.8099\n",
      "Epoch 135/200\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.1455 - auc_01: 0.8864 - auc: 0.9696 - val_loss: 0.5154 - val_auc_01: 0.6942 - val_auc: 0.8084\n",
      "Epoch 136/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1407 - auc_01: 0.8965 - auc: 0.9708 - val_loss: 0.5011 - val_auc_01: 0.7002 - val_auc: 0.8141\n",
      "Epoch 137/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1473 - auc_01: 0.8923 - auc: 0.9680 - val_loss: 0.4785 - val_auc_01: 0.7043 - val_auc: 0.8263\n",
      "Epoch 138/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1371 - auc_01: 0.9073 - auc: 0.9708 - val_loss: 0.5110 - val_auc_01: 0.6973 - val_auc: 0.8128\n",
      "Epoch 139/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1475 - auc_01: 0.8934 - auc: 0.9677 - val_loss: 0.5065 - val_auc_01: 0.7099 - val_auc: 0.8162\n",
      "Epoch 140/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1459 - auc_01: 0.8914 - auc: 0.9685 - val_loss: 0.5297 - val_auc_01: 0.6894 - val_auc: 0.8078\n",
      "Epoch 141/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1354 - auc_01: 0.9052 - auc: 0.9735 - val_loss: 0.5098 - val_auc_01: 0.6939 - val_auc: 0.8156\n",
      "Epoch 142/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1388 - auc_01: 0.9023 - auc: 0.9702 - val_loss: 0.5107 - val_auc_01: 0.6955 - val_auc: 0.8122\n",
      "Epoch 143/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1375 - auc_01: 0.9027 - auc: 0.9712 - val_loss: 0.5258 - val_auc_01: 0.7002 - val_auc: 0.8084\n",
      "Epoch 144/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1339 - auc_01: 0.9047 - auc: 0.9735 - val_loss: 0.5272 - val_auc_01: 0.6933 - val_auc: 0.8097\n",
      "Epoch 145/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1388 - auc_01: 0.9003 - auc: 0.9722 - val_loss: 0.5426 - val_auc_01: 0.6943 - val_auc: 0.8057\n",
      "Epoch 146/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1386 - auc_01: 0.9024 - auc: 0.9716 - val_loss: 0.5489 - val_auc_01: 0.6963 - val_auc: 0.8033\n",
      "Epoch 147/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1363 - auc_01: 0.9062 - auc: 0.9719 - val_loss: 0.5287 - val_auc_01: 0.6888 - val_auc: 0.8107\n",
      "Epoch 148/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1315 - auc_01: 0.9150 - auc: 0.9756 - val_loss: 0.5294 - val_auc_01: 0.6963 - val_auc: 0.8157\n",
      "Epoch 149/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1398 - auc_01: 0.9085 - auc: 0.9727 - val_loss: 0.5287 - val_auc_01: 0.6984 - val_auc: 0.8142\n",
      "Epoch 150/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1410 - auc_01: 0.8990 - auc: 0.9697 - val_loss: 0.5177 - val_auc_01: 0.7002 - val_auc: 0.8157\n",
      "Epoch 151/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1421 - auc_01: 0.8960 - auc: 0.9685 - val_loss: 0.5201 - val_auc_01: 0.6918 - val_auc: 0.8142\n",
      "Epoch 152/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1315 - auc_01: 0.9063 - auc: 0.9754 - val_loss: 0.5217 - val_auc_01: 0.6970 - val_auc: 0.8136\n",
      "Epoch 153/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1219 - auc_01: 0.9221 - auc: 0.9793 - val_loss: 0.5860 - val_auc_01: 0.6965 - val_auc: 0.8005\n",
      "Epoch 154/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1345 - auc_01: 0.9087 - auc: 0.9725 - val_loss: 0.5766 - val_auc_01: 0.6902 - val_auc: 0.8033\n",
      "Epoch 155/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1268 - auc_01: 0.9155 - auc: 0.9768 - val_loss: 0.6009 - val_auc_01: 0.6855 - val_auc: 0.7983\n",
      "Epoch 156/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1275 - auc_01: 0.9177 - auc: 0.9765 - val_loss: 0.5579 - val_auc_01: 0.6916 - val_auc: 0.8043\n",
      "Epoch 157/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1324 - auc_01: 0.9099 - auc: 0.9729 - val_loss: 0.5588 - val_auc_01: 0.6966 - val_auc: 0.8044\n",
      "Epoch 158/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1405 - auc_01: 0.9039 - auc: 0.9718 - val_loss: 0.5821 - val_auc_01: 0.6916 - val_auc: 0.7947\n",
      "Epoch 159/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1261 - auc_01: 0.9130 - auc: 0.9773 - val_loss: 0.5717 - val_auc_01: 0.6905 - val_auc: 0.7974\n",
      "Epoch 160/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1244 - auc_01: 0.9184 - auc: 0.9763 - val_loss: 0.5891 - val_auc_01: 0.6860 - val_auc: 0.8053\n",
      "Epoch 161/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1256 - auc_01: 0.9225 - auc: 0.9767 - val_loss: 0.5449 - val_auc_01: 0.7015 - val_auc: 0.8110\n",
      "Epoch 162/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1196 - auc_01: 0.9243 - auc: 0.9797 - val_loss: 0.5599 - val_auc_01: 0.6891 - val_auc: 0.8107\n",
      "Epoch 163/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1254 - auc_01: 0.9196 - auc: 0.9770 - val_loss: 0.5559 - val_auc_01: 0.6902 - val_auc: 0.8113\n",
      "Epoch 164/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1264 - auc_01: 0.9252 - auc: 0.9768 - val_loss: 0.5162 - val_auc_01: 0.6915 - val_auc: 0.8181\n",
      "Epoch 165/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1329 - auc_01: 0.9091 - auc: 0.9732 - val_loss: 0.5673 - val_auc_01: 0.6909 - val_auc: 0.8026\n",
      "Epoch 166/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1237 - auc_01: 0.9182 - auc: 0.9767 - val_loss: 0.5953 - val_auc_01: 0.6909 - val_auc: 0.7999\n",
      "Epoch 167/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1227 - auc_01: 0.9248 - auc: 0.9785 - val_loss: 0.5562 - val_auc_01: 0.6964 - val_auc: 0.8023\n",
      "Epoch 168/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1250 - auc_01: 0.9219 - auc: 0.9770 - val_loss: 0.5678 - val_auc_01: 0.6889 - val_auc: 0.8027\n",
      "Epoch 169/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1203 - auc_01: 0.9231 - auc: 0.9796 - val_loss: 0.5529 - val_auc_01: 0.6900 - val_auc: 0.8109\n",
      "Epoch 170/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1132 - auc_01: 0.9324 - auc: 0.9825 - val_loss: 0.5767 - val_auc_01: 0.6932 - val_auc: 0.8064\n",
      "Epoch 171/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1169 - auc_01: 0.9248 - auc: 0.9784 - val_loss: 0.5912 - val_auc_01: 0.6881 - val_auc: 0.7954\n",
      "Epoch 172/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1128 - auc_01: 0.9326 - auc: 0.9819 - val_loss: 0.5635 - val_auc_01: 0.6960 - val_auc: 0.8068\n",
      "Epoch 173/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1207 - auc_01: 0.9333 - auc: 0.9786 - val_loss: 0.5557 - val_auc_01: 0.6968 - val_auc: 0.8090\n",
      "Epoch 174/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1201 - auc_01: 0.9214 - auc: 0.9788 - val_loss: 0.5556 - val_auc_01: 0.6921 - val_auc: 0.8168\n",
      "Epoch 175/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1153 - auc_01: 0.9258 - auc: 0.9803 - val_loss: 0.5773 - val_auc_01: 0.6885 - val_auc: 0.8057\n",
      "Epoch 176/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1191 - auc_01: 0.9265 - auc: 0.9791 - val_loss: 0.5382 - val_auc_01: 0.6879 - val_auc: 0.8162\n",
      "Epoch 177/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1238 - auc_01: 0.9231 - auc: 0.9777 - val_loss: 0.5997 - val_auc_01: 0.6896 - val_auc: 0.8074\n",
      "Epoch 178/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1176 - auc_01: 0.9279 - auc: 0.9809 - val_loss: 0.5852 - val_auc_01: 0.6912 - val_auc: 0.8037\n",
      "Epoch 179/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1137 - auc_01: 0.9309 - auc: 0.9807 - val_loss: 0.5970 - val_auc_01: 0.6891 - val_auc: 0.7995\n",
      "Epoch 180/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1173 - auc_01: 0.9249 - auc: 0.9799 - val_loss: 0.6279 - val_auc_01: 0.6938 - val_auc: 0.7947\n",
      "Epoch 181/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1227 - auc_01: 0.9236 - auc: 0.9786 - val_loss: 0.5973 - val_auc_01: 0.6892 - val_auc: 0.8009\n",
      "Epoch 182/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1170 - auc_01: 0.9299 - auc: 0.9809 - val_loss: 0.5812 - val_auc_01: 0.6911 - val_auc: 0.8051\n",
      "Epoch 183/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1185 - auc_01: 0.9267 - auc: 0.9793 - val_loss: 0.5239 - val_auc_01: 0.7002 - val_auc: 0.8144\n",
      "Epoch 184/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1155 - auc_01: 0.9304 - auc: 0.9817 - val_loss: 0.5456 - val_auc_01: 0.7050 - val_auc: 0.8128\n",
      "Epoch 185/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1193 - auc_01: 0.9310 - auc: 0.9802 - val_loss: 0.5649 - val_auc_01: 0.6975 - val_auc: 0.7996\n",
      "Epoch 186/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1170 - auc_01: 0.9280 - auc: 0.9798 - val_loss: 0.5864 - val_auc_01: 0.6985 - val_auc: 0.7998\n",
      "Epoch 187/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1066 - auc_01: 0.9345 - auc: 0.9842 - val_loss: 0.5714 - val_auc_01: 0.7012 - val_auc: 0.8092\n",
      "Epoch 188/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1173 - auc_01: 0.9256 - auc: 0.9816 - val_loss: 0.5710 - val_auc_01: 0.7051 - val_auc: 0.8111\n",
      "Epoch 189/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1149 - auc_01: 0.9242 - auc: 0.9789 - val_loss: 0.5734 - val_auc_01: 0.6931 - val_auc: 0.8030\n",
      "Epoch 190/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1103 - auc_01: 0.9320 - auc: 0.9819 - val_loss: 0.5804 - val_auc_01: 0.7032 - val_auc: 0.8038\n",
      "Epoch 191/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1141 - auc_01: 0.9274 - auc: 0.9811 - val_loss: 0.5845 - val_auc_01: 0.6947 - val_auc: 0.8073\n",
      "Epoch 192/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1081 - auc_01: 0.9392 - auc: 0.9837 - val_loss: 0.5826 - val_auc_01: 0.7011 - val_auc: 0.8102\n",
      "Epoch 193/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1116 - auc_01: 0.9344 - auc: 0.9819 - val_loss: 0.5786 - val_auc_01: 0.6961 - val_auc: 0.8110\n",
      "Epoch 194/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1064 - auc_01: 0.9342 - auc: 0.9837 - val_loss: 0.5853 - val_auc_01: 0.6990 - val_auc: 0.8064\n",
      "Epoch 195/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1091 - auc_01: 0.9347 - auc: 0.9822 - val_loss: 0.5869 - val_auc_01: 0.6996 - val_auc: 0.8048\n",
      "Epoch 196/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1080 - auc_01: 0.9343 - auc: 0.9829 - val_loss: 0.5969 - val_auc_01: 0.6931 - val_auc: 0.8072\n",
      "Epoch 197/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1063 - auc_01: 0.9355 - auc: 0.9830 - val_loss: 0.5954 - val_auc_01: 0.6977 - val_auc: 0.8090\n",
      "Epoch 198/200\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1055 - auc_01: 0.9421 - auc: 0.9828 - val_loss: 0.5600 - val_auc_01: 0.7017 - val_auc: 0.8083\n",
      "Epoch 199/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1049 - auc_01: 0.9428 - auc: 0.9842 - val_loss: 0.6055 - val_auc_01: 0.6949 - val_auc: 0.8052\n",
      "Epoch 200/200\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.1076 - auc_01: 0.9308 - auc: 0.9834 - val_loss: 0.5906 - val_auc_01: 0.7058 - val_auc: 0.8104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 36). These functions will not be directly callable after loading.\n",
      "2024-12-04 23:19:45.193706: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2024-12-04 23:19:45.193730: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2024-12-04 23:19:45.194317: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpoqlw5kcp\n",
      "2024-12-04 23:19:45.203041: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-12-04 23:19:45.203054: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpoqlw5kcp\n",
      "2024-12-04 23:19:45.230716: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2024-12-04 23:19:45.238878: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2024-12-04 23:19:45.481385: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/tmpoqlw5kcp\n",
      "2024-12-04 23:19:45.539164: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 344850 microseconds.\n",
      "2024-12-04 23:19:45.672340: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(1500x1000)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "train_val, test = train_test_split(data, test_size=0.2, random_state=42)  # 20% data as test set\n",
    "\n",
    "# 5-fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# train_val data split\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
    "    # create output directory\n",
    "    outdir = f'results/fold_{fold}'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "\n",
    "    # split data\n",
    "    train_data = data.iloc[train_idx]\n",
    "    val_data = data.iloc[val_idx]\n",
    "\n",
    "    # save data\n",
    "    train_file = f'{outdir}/train_fold_{fold}.csv'\n",
    "    val_file = f'{outdir}/val_fold_{fold}.csv'\n",
    "    train_data.to_csv(train_file, index=False)\n",
    "    val_data.to_csv(val_file, index=False)\n",
    "\n",
    "    # train model\n",
    "    cmd = f\"python src/train_nettcr_2_2_pan.py --train_data {train_file} \" \\\n",
    "          f\"--val_data {val_file} --outdir {outdir} \" \\\n",
    "          f\"--model_name model_1204_fold_{fold} --epochs 200 \" \\\n",
    "          f\"--batch_size 64 --learning_rate 0.001 --dropout_rate 0.6 \" \\\n",
    "          f\"--patience 100 --verbose 1\"\n",
    "\n",
    "    # \n",
    "    subprocess.run(cmd, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.073 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.072 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.074 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict\n",
    "test_file = f'{outdir}/test.csv'\n",
    "test.to_csv(test_file, index=False)\n",
    "\n",
    "for fold in range(5):\n",
    "    outdir = f'results/fold_{fold}'\n",
    "    cmd = f\"python src/predict.py --test_data {test_file} --outdir {outdir} \" \\\n",
    "          f\"--model_name model_1204_fold_{fold} --model_type pan\"\n",
    "    subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   binder  prediction\n",
      "0       0    0.009128\n",
      "1       0    0.024446\n",
      "2       0    0.011468\n",
      "3       0    0.152820\n",
      "4       0    0.000428\n",
      "Full AUC: 0.9939965432325364\n",
      "AUC 0.1: 0.9773768496402757\n",
      "Precision: 0.9615384615384616\n",
      "Recall: 0.8771929824561403\n",
      "F1 Score: 0.9174311926605504\n",
      "Specificity: 0.993025283347864\n",
      "Accuracy: 0.9738181818181818\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ds = 4\n",
    "file_path = f'results/fold_{ds}/model_1204_fold_{ds}_prediction.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'binder': data['binder'],  # \n",
    "    'prediction': data['prediction']  # \n",
    "})\n",
    "\n",
    "# \n",
    "print(df.head())\n",
    "\n",
    "# y_true and y_scores\n",
    "y_true = df['binder']\n",
    "y_scores = df['prediction']\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# full auc\n",
    "full_auc = roc_auc_score(y_true, y_scores)\n",
    "print(\"Full AUC:\", full_auc)\n",
    "\n",
    "# auc 0.1\n",
    "auc_01 = roc_auc_score(y_true, y_scores, max_fpr = 0.1)\n",
    "print(\"AUC 0.1:\", auc_01)\n",
    "\n",
    "# precision and recall\n",
    "precision = precision_score(y_true, y_scores >= 0.5)  # threshold 0.5\n",
    "recall = recall_score(y_true, y_scores >= 0.5)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(y_true, y_scores >= 0.5)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# specificity\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_scores >= 0.5).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_true, y_scores >= 0.5)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Full AUC: 0.8181985041068232\n",
      "Fold 0 AUC 0.1: 0.6901829897093948\n",
      "Fold 1 Full AUC: 0.9898935437984674\n",
      "Fold 1 AUC 0.1: 0.9581086313728616\n",
      "Fold 2 Full AUC: 0.9988681380871534\n",
      "Fold 2 AUC 0.1: 0.9940428320376493\n",
      "Fold 3 Full AUC: 0.99890637666529\n",
      "Fold 3 AUC 0.1: 0.9942440877120531\n",
      "Fold 4 Full AUC: 0.9939965432325364\n",
      "Fold 4 AUC 0.1: 0.9773768496402757\n",
      "   Fold       AUC   AUC_0.1\n",
      "0   0.0  0.818199  0.690183\n",
      "1   1.0  0.989894  0.958109\n",
      "2   2.0  0.998868  0.994043\n",
      "3   3.0  0.998906  0.994244\n",
      "4   4.0  0.993997  0.977377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/ipykernel_25977/54992578.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Fold': fold, 'AUC': full_auc, 'AUC_0.1': auc_01}, ignore_index=True)\n",
      "/var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/ipykernel_25977/54992578.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Fold': fold, 'AUC': full_auc, 'AUC_0.1': auc_01}, ignore_index=True)\n",
      "/var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/ipykernel_25977/54992578.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Fold': fold, 'AUC': full_auc, 'AUC_0.1': auc_01}, ignore_index=True)\n",
      "/var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/ipykernel_25977/54992578.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Fold': fold, 'AUC': full_auc, 'AUC_0.1': auc_01}, ignore_index=True)\n",
      "/var/folders/0f/qywr9xws0sx43t5v5n2ttn540000gn/T/ipykernel_25977/54992578.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Fold': fold, 'AUC': full_auc, 'AUC_0.1': auc_01}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calculate_metrics(num_folds):\n",
    "    \n",
    "    results = pd.DataFrame(columns=['Fold', 'AUC', 'AUC_0.1'])\n",
    "\n",
    "    for fold in range(num_folds):\n",
    "        file_path = f'results/fold_{fold}/model_1204_fold_{fold}_prediction.csv'\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'binder': data['binder'],  \n",
    "            'prediction': data['prediction']  \n",
    "        })\n",
    "\n",
    "        # \n",
    "        y_true = df['binder']\n",
    "        y_scores = df['prediction']\n",
    "\n",
    "        # \n",
    "        full_auc = roc_auc_score(y_true, y_scores)\n",
    "        print(f\"Fold {fold} Full AUC:\", full_auc)\n",
    "\n",
    "        # AUC 0.1\n",
    "        #fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "        # auc_01 = auc(fpr[fpr <= 0.1], tpr[fpr <= 0.1])\n",
    "        auc_01 = roc_auc_score(y_true, y_scores, max_fpr = 0.1)\n",
    "        print(f\"Fold {fold} AUC 0.1:\", auc_01)\n",
    "\n",
    "        # \n",
    "        results = results.append({'Fold': fold, 'AUC': full_auc, 'AUC_0.1': auc_01}, ignore_index=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "# \n",
    "num_folds = 5\n",
    "results_df = calculate_metrics(num_folds)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
